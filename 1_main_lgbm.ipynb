{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from preprocess.preprocess_transaction_frequecy import preprocess_transaction_frequency\n",
    "from preprocess.preprocess_init import preprocess_init\n",
    "from preprocess.preprocess_time import preprocess_time\n",
    "from preprocess.preprocess_change_card import preprocess_change_card\n",
    "from preprocess.preprocess_mchno import preprocess_mchno\n",
    "from preprocess.preprocess_special_features import preprocess_special_features\n",
    "from preprocess.preprocess_conam import preprocess_conam\n",
    "from preprocess.preprocess_train_test_split import preprocess_train_test_split\n",
    "\n",
    "from util.generate_X_y import generate_X_y\n",
    "from util.remove_outlier import remove_outlier\n",
    "from util.generate_statistic import generate_statistic\n",
    "\n",
    "from model.lgbm_model import LGBM_Model\n",
    "from model.shap_importance import shap_importance\n",
    "from model.plot import plot_importance\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running the following program , please make sure \n",
    "### that the features create from new_features.ipynb complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total: 5 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Base model: Created by base features which contain 20 raw features , 13 preprocessed features and 60 preprocess frequent features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Special features: 4 special features to capture the information of the label, since there are some users(bacno) in both training and testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each of the four models is trained by the base features plus one special feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the transaction in testing meets the conditions of special features, the transaction is predicted by the corresponding special model. Otherwise the transaction is predicted by the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: These special features may not work in real world since we don't suppose have the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply limited number of new features \n",
    "    - In order to simplify models to have better generalizaiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace the value of categorical features of training set with NA if the value is not in testing set\n",
    "    - The model will not learn something useless when apply in testing set. The model can focus on the value which also exists in testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use early stopping and split the training set by GroupKFold\n",
    "    - The model will stop training once the model performance stops improving on a hold out validation dataset.\n",
    "    - Grouping the training set by user(bacno) makes the model stop earlier which prevents overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop extreme cases\n",
    "    - Drop the prediction of the fold if it is out of 1 standard deviation boundary, since some of the predictions of testing set are very extreme between folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the features i used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_bool_features = ['ecfg',\n",
    "                     'flbmk',\n",
    "                     'flg_3dsmk',\n",
    "                     'insfg',\n",
    "                     'ovrlt'\n",
    "                      ]\n",
    "\n",
    "raw_categorial_features = ['contp',\n",
    "                           'stscd',\n",
    "                           'etymd',\n",
    "                           'stocn',\n",
    "                           'mcc',\n",
    "                           'csmcu',\n",
    "                           'hcefg',\n",
    "                           'bacno',\n",
    "                           'cano',\n",
    "                           'mchno',\n",
    "                           'acqic',\n",
    "                           'scity'\n",
    "                            ] \n",
    "\n",
    "raw_contiuous_feautres = ['loctm',\n",
    "                          'conam',\n",
    "                          'iterm'\n",
    "                           ]\n",
    "\n",
    "transaction_frequency_feautres = ['cano_days_txkey_count',#同卡號，同一週期(30/60/90)出現的次數\n",
    "                                  'cano_locdt_txkey_count',#同卡號，同一天出現的次數\n",
    "                                  'bacno_locdt_mchno_txkey_count'#同帳號，同一天，同特店出現的次數\n",
    "                                    ]\n",
    "\n",
    "time_feautres = ['last_time_days',\n",
    "                 'next_time_days',\n",
    "                 'cano_locdt_global_time_std' \n",
    "                    ]\n",
    "\n",
    "\n",
    "change_card_feautres = ['diff_locdt_with_last_trans_cano',\n",
    "                        'diff_locdt_of_two_card'\n",
    "                           ]\n",
    "\n",
    "conam_feautres = ['cano_locdt_conam_min',\n",
    "                  'cano_locdt_conam_max',\n",
    "                  'diff_gtime_with_conam_zero_trans_locdt'\n",
    "                   ]\n",
    "\n",
    "mchno_features = ['bacno_mchno_locdt_head_tail_diff',\n",
    "                  'cano_days_mchno_index',    \n",
    "                    ]\n",
    "\n",
    "\n",
    "special_feautures = ['mchno_in_normal_mchno_list',# 這間特電在過去的交易中有出現且是正常的\n",
    "                    'mchno_in_fraud_mchno_list',# 這間特電在過去的交易中有出現且是盜刷的\n",
    "                    'conam_in_fraud_conam_list',# 金額在過去的交易中有出現且是異常的\n",
    "                    'diff_with_first_fraud_locdt'#與該卡號第一次被判盜刷距今的交易時間 \n",
    "                               ]\n",
    "new_features = ['bacno_cano_conam_mean_1h', 'bacno_cano_count_sum_1h',\n",
    "       'bacno_cano_conam_mean_6h', 'bacno_cano_count_sum_6h',\n",
    "       'bacno_cano_conam_mean_1d', 'bacno_cano_count_sum_1d',\n",
    "       'bacno_cano_conam_mean_30d', 'bacno_cano_count_sum_30d',\n",
    "       'bacno_cano_conam_mean_7d', 'bacno_cano_count_sum_7d',\n",
    "       'bacno_cano_conam_mean_120d', 'bacno_cano_count_sum_120d',\n",
    "       'bacno_cano_conam_mean_1h_xg_conam',\n",
    "       'bacno_cano_conam_mean_6h_xg_conam',\n",
    "       'bacno_cano_conam_mean_1d_xg_conam',\n",
    "       'bacno_cano_conam_mean_7d_xg_conam',\n",
    "       'bacno_cano_conam_mean_30d_xg_conam',\n",
    "       'bacno_cano_conam_mean_120d_xg_conam', 'bacno_cano_count_sum_7d_xg_1h',\n",
    "       'bacno_cano_count_sum_1d_xg_1h', 'bacno_cano_count_sum_6h_xg_1h',\n",
    "       'bacno_cano_conam_mean_1h_div_conam',\n",
    "       'bacno_cano_conam_mean_6h_div_conam',\n",
    "       'bacno_cano_conam_mean_1d_div_conam',\n",
    "       'bacno_cano_conam_mean_7d_div_conam',\n",
    "       'bacno_cano_conam_mean_30d_div_conam',\n",
    "       'bacno_cano_conam_mean_120d_div_conam']\n",
    "new2_features = ['cano_mhcno_conam_mean_1h', 'cano_mhcno_count_sum_1h',\n",
    "       'cano_mhcno_conam_mean_6h', 'cano_mhcno_count_sum_6h',\n",
    "       'cano_mhcno_conam_mean_1d', 'cano_mhcno_count_sum_1d',\n",
    "       'cano_mhcno_conam_mean_7d', 'cano_mhcno_count_sum_7d',\n",
    "       'cano_mhcno_conam_mean_30d', 'cano_mhcno_count_sum_30d',\n",
    "       'cano_mhcno_conam_mean_120d', 'cano_mhcno_count_sum_120d',\n",
    "       'cano_mchno_conam_mean_1h_xg_conam',\n",
    "       'cano_mchno_conam_mean_6h_xg_conam',\n",
    "       'cano_mchno_conam_mean_1d_xg_conam',\n",
    "       'cano_mchno_conam_mean_7d_xg_conam',\n",
    "       'cano_mchno_conam_mean_30d_xg_conam',\n",
    "       'cano_mchno_conam_mean_120d_xg_conam', 'cano_mhcno_count_sum_7d_xg_1h',\n",
    "       'cano_mhcno_count_sum_1d_xg_1h', 'cano_mhcno_count_sum_6h_xg_1h',\n",
    "       'cano_mhcno_conam_mean_1h_div_conam',\n",
    "       'cano_mhcno_conam_mean_6h_div_conam',\n",
    "       'cano_mhcno_conam_mean_1d_div_conam',\n",
    "       'cano_mhcno_conam_mean_7d_div_conam',\n",
    "       'cano_mhcno_conam_mean_30d_div_conam',\n",
    "       'cano_mhcno_conam_mean_120d_div_conam']\n",
    "new3_features = ['bacno_cano_stocn_unique_2d', 'bacno_cano_stocn_unique_6h',\n",
    "       'bacno_cano_mchno_unique_2d', 'bacno_cano_mchno_unique_6h',\n",
    "       'bacno_cano_mcc_unique_2d', 'bacno_cano_mcc_unique_6h']\n",
    "\n",
    "base_features =  (    raw_bool_features \n",
    "                    + raw_categorial_features\n",
    "                    + raw_contiuous_feautres\n",
    "                    + transaction_frequency_feautres\n",
    "                    + time_feautres\n",
    "                    + change_card_feautres\n",
    "                    + conam_feautres \n",
    "                    + mchno_features + new_features +new2_features +new3_features\n",
    "                       )\n",
    "\n",
    "label = 'fraud_ind'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_group = False\n",
    "if preprocess_group:\n",
    "    df_train_raw = pd.read_csv('data/train.csv')\n",
    "    df_test_raw = pd.read_csv('data/test.csv')\n",
    "    df = preprocess_init(df_train_raw, df_test_raw, raw_bool_features)\n",
    "    df = preprocess_transaction_frequency(df)\n",
    "    df = preprocess_time(df)\n",
    "    df = preprocess_change_card(df)\n",
    "    df = preprocess_mchno(df)\n",
    "    df = preprocess_conam(df)\n",
    "    df = preprocess_special_features(df)\n",
    "    df.to_pickle('data/df_preprocessed.pkl')\n",
    "else:\n",
    "    df = pd.read_pickle('data/df_preprocessed.pkl')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_x = pd.read_csv('new_x_bacno_cano_conam.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2_x = pd.read_csv('new2_x_cano_mhcno_conam.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new3_x = pd.read_csv('new3_x_bacno_cano_category_count.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df , df_new_x,on='txkey' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df , df_new2_x,on='txkey' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df , df_new3_x,on='txkey' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns) #確認合併是一樣的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecfg</th>\n",
       "      <th>flbmk</th>\n",
       "      <th>flg_3dsmk</th>\n",
       "      <th>insfg</th>\n",
       "      <th>ovrlt</th>\n",
       "      <th>contp</th>\n",
       "      <th>stscd</th>\n",
       "      <th>etymd</th>\n",
       "      <th>stocn</th>\n",
       "      <th>mcc</th>\n",
       "      <th>csmcu</th>\n",
       "      <th>hcefg</th>\n",
       "      <th>bacno</th>\n",
       "      <th>cano</th>\n",
       "      <th>mchno</th>\n",
       "      <th>acqic</th>\n",
       "      <th>scity</th>\n",
       "      <th>loctm</th>\n",
       "      <th>conam</th>\n",
       "      <th>iterm</th>\n",
       "      <th>cano_days_txkey_count</th>\n",
       "      <th>cano_locdt_txkey_count</th>\n",
       "      <th>bacno_locdt_mchno_txkey_count</th>\n",
       "      <th>last_time_days</th>\n",
       "      <th>next_time_days</th>\n",
       "      <th>cano_locdt_global_time_std</th>\n",
       "      <th>diff_locdt_with_last_trans_cano</th>\n",
       "      <th>diff_locdt_of_two_card</th>\n",
       "      <th>cano_locdt_conam_min</th>\n",
       "      <th>cano_locdt_conam_max</th>\n",
       "      <th>diff_gtime_with_conam_zero_trans_locdt</th>\n",
       "      <th>bacno_mchno_locdt_head_tail_diff</th>\n",
       "      <th>cano_days_mchno_index</th>\n",
       "      <th>bacno_cano_conam_mean_1h</th>\n",
       "      <th>bacno_cano_count_sum_1h</th>\n",
       "      <th>bacno_cano_conam_mean_6h</th>\n",
       "      <th>bacno_cano_count_sum_6h</th>\n",
       "      <th>bacno_cano_conam_mean_1d</th>\n",
       "      <th>bacno_cano_count_sum_1d</th>\n",
       "      <th>bacno_cano_conam_mean_30d</th>\n",
       "      <th>bacno_cano_count_sum_30d</th>\n",
       "      <th>bacno_cano_conam_mean_7d</th>\n",
       "      <th>bacno_cano_count_sum_7d</th>\n",
       "      <th>bacno_cano_conam_mean_120d</th>\n",
       "      <th>bacno_cano_count_sum_120d</th>\n",
       "      <th>bacno_cano_conam_mean_1h_xg_conam</th>\n",
       "      <th>bacno_cano_conam_mean_6h_xg_conam</th>\n",
       "      <th>bacno_cano_conam_mean_1d_xg_conam</th>\n",
       "      <th>bacno_cano_conam_mean_7d_xg_conam</th>\n",
       "      <th>bacno_cano_conam_mean_30d_xg_conam</th>\n",
       "      <th>bacno_cano_conam_mean_120d_xg_conam</th>\n",
       "      <th>bacno_cano_count_sum_7d_xg_1h</th>\n",
       "      <th>bacno_cano_count_sum_1d_xg_1h</th>\n",
       "      <th>bacno_cano_count_sum_6h_xg_1h</th>\n",
       "      <th>bacno_cano_conam_mean_1h_div_conam</th>\n",
       "      <th>bacno_cano_conam_mean_6h_div_conam</th>\n",
       "      <th>bacno_cano_conam_mean_1d_div_conam</th>\n",
       "      <th>bacno_cano_conam_mean_7d_div_conam</th>\n",
       "      <th>bacno_cano_conam_mean_30d_div_conam</th>\n",
       "      <th>bacno_cano_conam_mean_120d_div_conam</th>\n",
       "      <th>cano_mhcno_conam_mean_1h</th>\n",
       "      <th>cano_mhcno_count_sum_1h</th>\n",
       "      <th>cano_mhcno_conam_mean_6h</th>\n",
       "      <th>cano_mhcno_count_sum_6h</th>\n",
       "      <th>cano_mhcno_conam_mean_1d</th>\n",
       "      <th>cano_mhcno_count_sum_1d</th>\n",
       "      <th>cano_mhcno_conam_mean_7d</th>\n",
       "      <th>cano_mhcno_count_sum_7d</th>\n",
       "      <th>cano_mhcno_conam_mean_30d</th>\n",
       "      <th>cano_mhcno_count_sum_30d</th>\n",
       "      <th>cano_mhcno_conam_mean_120d</th>\n",
       "      <th>cano_mhcno_count_sum_120d</th>\n",
       "      <th>cano_mchno_conam_mean_1h_xg_conam</th>\n",
       "      <th>cano_mchno_conam_mean_6h_xg_conam</th>\n",
       "      <th>cano_mchno_conam_mean_1d_xg_conam</th>\n",
       "      <th>cano_mchno_conam_mean_7d_xg_conam</th>\n",
       "      <th>cano_mchno_conam_mean_30d_xg_conam</th>\n",
       "      <th>cano_mchno_conam_mean_120d_xg_conam</th>\n",
       "      <th>cano_mhcno_count_sum_7d_xg_1h</th>\n",
       "      <th>cano_mhcno_count_sum_1d_xg_1h</th>\n",
       "      <th>cano_mhcno_count_sum_6h_xg_1h</th>\n",
       "      <th>cano_mhcno_conam_mean_1h_div_conam</th>\n",
       "      <th>cano_mhcno_conam_mean_6h_div_conam</th>\n",
       "      <th>cano_mhcno_conam_mean_1d_div_conam</th>\n",
       "      <th>cano_mhcno_conam_mean_7d_div_conam</th>\n",
       "      <th>cano_mhcno_conam_mean_30d_div_conam</th>\n",
       "      <th>cano_mhcno_conam_mean_120d_div_conam</th>\n",
       "      <th>bacno_cano_stocn_unique_2d</th>\n",
       "      <th>bacno_cano_stocn_unique_6h</th>\n",
       "      <th>bacno_cano_mchno_unique_2d</th>\n",
       "      <th>bacno_cano_mchno_unique_6h</th>\n",
       "      <th>bacno_cano_mcc_unique_2d</th>\n",
       "      <th>bacno_cano_mcc_unique_6h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1943429</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47022</td>\n",
       "      <td>6716.0</td>\n",
       "      <td>4526.0</td>\n",
       "      <td>202808.0</td>\n",
       "      <td>815.08</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>815.08</td>\n",
       "      <td>815.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>815.080000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>815.080000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>815.080000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>619.404000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>782.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>788.288235</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>3.224667e+01</td>\n",
       "      <td>195.676000</td>\n",
       "      <td>26.791765</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.041192</td>\n",
       "      <td>1.315910</td>\n",
       "      <td>1.033987</td>\n",
       "      <td>815.080000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>815.080000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>815.080000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>815.080000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>815.080000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>815.080000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943430</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38207</td>\n",
       "      <td>6322.0</td>\n",
       "      <td>5817.0</td>\n",
       "      <td>61702.0</td>\n",
       "      <td>750.24</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-46675.0</td>\n",
       "      <td>29430.624781</td>\n",
       "      <td>-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>381.65</td>\n",
       "      <td>841.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>750.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>750.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>657.790000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>774.685000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>786.174444</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-2.444500e+01</td>\n",
       "      <td>92.450000</td>\n",
       "      <td>-35.934444</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968445</td>\n",
       "      <td>1.140546</td>\n",
       "      <td>0.954292</td>\n",
       "      <td>750.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>750.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>750.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>750.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>750.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>750.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943431</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39044</td>\n",
       "      <td>6716.0</td>\n",
       "      <td>5820.0</td>\n",
       "      <td>191457.0</td>\n",
       "      <td>841.64</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>46675.0</td>\n",
       "      <td>-7720.0</td>\n",
       "      <td>29430.624781</td>\n",
       "      <td>-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>381.65</td>\n",
       "      <td>841.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>841.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>841.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>795.940000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>674.503636</td>\n",
       "      <td>11.0</td>\n",
       "      <td>788.076000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>789.093684</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>4.570000e+01</td>\n",
       "      <td>5.356400e+01</td>\n",
       "      <td>167.136364</td>\n",
       "      <td>52.546316</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.057416</td>\n",
       "      <td>1.067968</td>\n",
       "      <td>1.247792</td>\n",
       "      <td>1.066591</td>\n",
       "      <td>841.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>841.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>841.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>841.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>841.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>841.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88672</td>\n",
       "      <td>5975.0</td>\n",
       "      <td>5817.0</td>\n",
       "      <td>212337.0</td>\n",
       "      <td>381.65</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7720.0</td>\n",
       "      <td>-84800.0</td>\n",
       "      <td>29430.624781</td>\n",
       "      <td>-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>381.65</td>\n",
       "      <td>841.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>381.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>611.645000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>657.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>650.099167</td>\n",
       "      <td>12.0</td>\n",
       "      <td>720.338333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>768.721500</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-2.299950e+02</td>\n",
       "      <td>-2.761933e+02</td>\n",
       "      <td>-3.386883e+02</td>\n",
       "      <td>-268.449167</td>\n",
       "      <td>-387.071500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623973</td>\n",
       "      <td>0.580153</td>\n",
       "      <td>0.529820</td>\n",
       "      <td>0.587064</td>\n",
       "      <td>0.496474</td>\n",
       "      <td>381.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>381.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>381.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>381.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>381.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>381.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5975.0</td>\n",
       "      <td>5817.0</td>\n",
       "      <td>205657.0</td>\n",
       "      <td>366.38</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84800.0</td>\n",
       "      <td>-240959.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366.38</td>\n",
       "      <td>366.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>366.380000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>366.380000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>374.015000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>623.760000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>669.772857</td>\n",
       "      <td>7.0</td>\n",
       "      <td>749.562381</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-7.635000e+00</td>\n",
       "      <td>-3.033929e+02</td>\n",
       "      <td>-257.380000</td>\n",
       "      <td>-383.182381</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979586</td>\n",
       "      <td>0.547021</td>\n",
       "      <td>0.587373</td>\n",
       "      <td>0.488792</td>\n",
       "      <td>366.380000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>366.380000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>366.380000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>366.380000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>366.380000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>366.380000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943434</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5975.0</td>\n",
       "      <td>5817.0</td>\n",
       "      <td>155256.0</td>\n",
       "      <td>1119.11</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>240959.0</td>\n",
       "      <td>-5347.0</td>\n",
       "      <td>3661.951802</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1103.64</td>\n",
       "      <td>1334.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1119.110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1119.110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1119.110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>661.863846</td>\n",
       "      <td>13.0</td>\n",
       "      <td>780.080000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>766.360000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>3.390300e+02</td>\n",
       "      <td>457.246154</td>\n",
       "      <td>352.750000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.434609</td>\n",
       "      <td>1.690846</td>\n",
       "      <td>1.460293</td>\n",
       "      <td>1119.110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1119.110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1119.110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1119.110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1119.110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1119.110000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6475</td>\n",
       "      <td>6767.0</td>\n",
       "      <td>5817.0</td>\n",
       "      <td>172203.0</td>\n",
       "      <td>1334.91</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5347.0</td>\n",
       "      <td>-2025.0</td>\n",
       "      <td>3661.951802</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1103.64</td>\n",
       "      <td>1334.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1334.910000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1227.010000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1227.010000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>709.938571</td>\n",
       "      <td>14.0</td>\n",
       "      <td>801.287143</td>\n",
       "      <td>7.0</td>\n",
       "      <td>791.079565</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>1.079000e+02</td>\n",
       "      <td>1.079000e+02</td>\n",
       "      <td>5.336229e+02</td>\n",
       "      <td>624.971429</td>\n",
       "      <td>543.830435</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.087937</td>\n",
       "      <td>1.087937</td>\n",
       "      <td>1.665957</td>\n",
       "      <td>1.880318</td>\n",
       "      <td>1.687454</td>\n",
       "      <td>1334.910000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1334.910000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1334.910000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1334.910000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1334.910000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1334.910000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6475</td>\n",
       "      <td>6767.0</td>\n",
       "      <td>5817.0</td>\n",
       "      <td>175548.0</td>\n",
       "      <td>1125.71</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>-735.0</td>\n",
       "      <td>3661.951802</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1103.64</td>\n",
       "      <td>1334.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1230.310000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1193.243333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1193.243333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>737.656667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>841.840000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>805.022500</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.046000e+02</td>\n",
       "      <td>-6.753333e+01</td>\n",
       "      <td>-6.753333e+01</td>\n",
       "      <td>2.838700e+02</td>\n",
       "      <td>388.053333</td>\n",
       "      <td>320.687500</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914981</td>\n",
       "      <td>0.943404</td>\n",
       "      <td>0.943404</td>\n",
       "      <td>1.337202</td>\n",
       "      <td>1.526062</td>\n",
       "      <td>1.398358</td>\n",
       "      <td>1230.310000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1230.310000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1230.310000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1230.310000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1230.310000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1230.310000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-104.600000</td>\n",
       "      <td>-104.600000</td>\n",
       "      <td>-104.600000</td>\n",
       "      <td>-104.600000</td>\n",
       "      <td>-104.600000</td>\n",
       "      <td>-104.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.914981</td>\n",
       "      <td>0.914981</td>\n",
       "      <td>0.914981</td>\n",
       "      <td>0.914981</td>\n",
       "      <td>0.914981</td>\n",
       "      <td>0.914981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943437</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6475</td>\n",
       "      <td>6767.0</td>\n",
       "      <td>5817.0</td>\n",
       "      <td>180803.0</td>\n",
       "      <td>1103.64</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>735.0</td>\n",
       "      <td>-749289.0</td>\n",
       "      <td>3661.951802</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1103.64</td>\n",
       "      <td>1334.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1188.086667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1170.842500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1170.842500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>760.530625</td>\n",
       "      <td>16.0</td>\n",
       "      <td>870.928889</td>\n",
       "      <td>9.0</td>\n",
       "      <td>816.967200</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-8.444667e+01</td>\n",
       "      <td>-6.720250e+01</td>\n",
       "      <td>-6.720250e+01</td>\n",
       "      <td>2.327111e+02</td>\n",
       "      <td>343.109375</td>\n",
       "      <td>286.672800</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928922</td>\n",
       "      <td>0.942603</td>\n",
       "      <td>0.942603</td>\n",
       "      <td>1.267199</td>\n",
       "      <td>1.451145</td>\n",
       "      <td>1.350899</td>\n",
       "      <td>1188.086667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1188.086667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1188.086667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1188.086667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1188.086667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1188.086667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-84.446667</td>\n",
       "      <td>-84.446667</td>\n",
       "      <td>-84.446667</td>\n",
       "      <td>-84.446667</td>\n",
       "      <td>-84.446667</td>\n",
       "      <td>-84.446667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928922</td>\n",
       "      <td>0.928922</td>\n",
       "      <td>0.928922</td>\n",
       "      <td>0.928922</td>\n",
       "      <td>0.928922</td>\n",
       "      <td>0.928922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943438</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82174</td>\n",
       "      <td>6769.0</td>\n",
       "      <td>5817.0</td>\n",
       "      <td>101612.0</td>\n",
       "      <td>1194.66</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>749289.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1194.66</td>\n",
       "      <td>1194.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1194.660000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1194.660000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1194.660000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>803.008667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1194.660000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>831.493846</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-1.136868e-12</td>\n",
       "      <td>-1.136868e-12</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>391.651333</td>\n",
       "      <td>363.166154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.487730</td>\n",
       "      <td>1.436763</td>\n",
       "      <td>1194.660000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1194.660000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1194.660000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1194.660000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1194.660000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1194.660000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ecfg  flbmk  flg_3dsmk  insfg  ovrlt contp stscd etymd  stocn    mcc  \\\n",
       "1943429     0      0          0      0      0   5.0   0.0   5.0  102.0  292.0   \n",
       "1943430     1      0          0      0      0   5.0   0.0   8.0  102.0  209.0   \n",
       "1943431     0      0          0      0      0   5.0   0.0   5.0  102.0  270.0   \n",
       "1943432     0      0          0      0      0   5.0   0.0   5.0  102.0  306.0   \n",
       "1943433     0      0          0      0      0   5.0   0.0   5.0  102.0  192.0   \n",
       "1943434     0      0          0      0      0   5.0   0.0   5.0  102.0  288.0   \n",
       "1943435     0      0          0      0      0   5.0   0.0   5.0  102.0  247.0   \n",
       "1943436     0      0          0      0      0   5.0   0.0   5.0  102.0  247.0   \n",
       "1943437     0      0          0      0      0   5.0   0.0   5.0  102.0  247.0   \n",
       "1943438     1      0          0      1      0   5.0   0.0   8.0  102.0  247.0   \n",
       "\n",
       "        csmcu hcefg bacno cano  mchno   acqic   scity     loctm    conam  \\\n",
       "1943429  62.0   5.0   NaN  NaN  47022  6716.0  4526.0  202808.0   815.08   \n",
       "1943430  62.0   5.0   NaN  NaN  38207  6322.0  5817.0   61702.0   750.24   \n",
       "1943431  62.0   5.0   NaN  NaN  39044  6716.0  5820.0  191457.0   841.64   \n",
       "1943432  62.0   5.0   NaN  NaN  88672  5975.0  5817.0  212337.0   381.65   \n",
       "1943433  62.0   5.0   NaN  NaN    NaN  5975.0  5817.0  205657.0   366.38   \n",
       "1943434  62.0   5.0   NaN  NaN    NaN  5975.0  5817.0  155256.0  1119.11   \n",
       "1943435  62.0   5.0   NaN  NaN   6475  6767.0  5817.0  172203.0  1334.91   \n",
       "1943436  62.0   5.0   NaN  NaN   6475  6767.0  5817.0  175548.0  1125.71   \n",
       "1943437  62.0   5.0   NaN  NaN   6475  6767.0  5817.0  180803.0  1103.64   \n",
       "1943438  62.0   5.0   NaN  NaN  82174  6769.0  5817.0  101612.0  1194.66   \n",
       "\n",
       "         iterm  cano_days_txkey_count  cano_locdt_txkey_count  \\\n",
       "1943429      0                      9                       1   \n",
       "1943430      0                      9                       3   \n",
       "1943431      0                      9                       3   \n",
       "1943432      0                      9                       3   \n",
       "1943433      0                      9                       1   \n",
       "1943434      0                      9                       4   \n",
       "1943435      0                      9                       4   \n",
       "1943436      0                      9                       4   \n",
       "1943437      0                      9                       4   \n",
       "1943438      1                      9                       1   \n",
       "\n",
       "         bacno_locdt_mchno_txkey_count  last_time_days  next_time_days  \\\n",
       "1943429                              1         99046.0             NaN   \n",
       "1943430                              1             NaN        -46675.0   \n",
       "1943431                              1         46675.0         -7720.0   \n",
       "1943432                              1          7720.0        -84800.0   \n",
       "1943433                              1         84800.0       -240959.0   \n",
       "1943434                              1        240959.0         -5347.0   \n",
       "1943435                              3          5347.0         -2025.0   \n",
       "1943436                              3          2025.0          -735.0   \n",
       "1943437                              3           735.0       -749289.0   \n",
       "1943438                              1        749289.0             NaN   \n",
       "\n",
       "         cano_locdt_global_time_std  diff_locdt_with_last_trans_cano  \\\n",
       "1943429                         NaN                                0   \n",
       "1943430                29430.624781                              -13   \n",
       "1943431                29430.624781                              -13   \n",
       "1943432                29430.624781                              -13   \n",
       "1943433                         NaN                              -12   \n",
       "1943434                 3661.951802                               -9   \n",
       "1943435                 3661.951802                               -9   \n",
       "1943436                 3661.951802                               -9   \n",
       "1943437                 3661.951802                               -9   \n",
       "1943438                         NaN                                0   \n",
       "\n",
       "         diff_locdt_of_two_card  cano_locdt_conam_min  cano_locdt_conam_max  \\\n",
       "1943429                     NaN                815.08                815.08   \n",
       "1943430                     NaN                381.65                841.64   \n",
       "1943431                     NaN                381.65                841.64   \n",
       "1943432                     NaN                381.65                841.64   \n",
       "1943433                     NaN                366.38                366.38   \n",
       "1943434                     NaN               1103.64               1334.91   \n",
       "1943435                     NaN               1103.64               1334.91   \n",
       "1943436                     NaN               1103.64               1334.91   \n",
       "1943437                     NaN               1103.64               1334.91   \n",
       "1943438                     NaN               1194.66               1194.66   \n",
       "\n",
       "         diff_gtime_with_conam_zero_trans_locdt  \\\n",
       "1943429                                     NaN   \n",
       "1943430                                     NaN   \n",
       "1943431                                     NaN   \n",
       "1943432                                     NaN   \n",
       "1943433                                     NaN   \n",
       "1943434                                     NaN   \n",
       "1943435                                     NaN   \n",
       "1943436                                     NaN   \n",
       "1943437                                     NaN   \n",
       "1943438                                     NaN   \n",
       "\n",
       "         bacno_mchno_locdt_head_tail_diff  cano_days_mchno_index  \\\n",
       "1943429                                 0                      1   \n",
       "1943430                                 0                      1   \n",
       "1943431                                 0                      1   \n",
       "1943432                                 0                      1   \n",
       "1943433                                 0                      1   \n",
       "1943434                                 0                      1   \n",
       "1943435                                 0                      1   \n",
       "1943436                                 0                      2   \n",
       "1943437                                 0                      3   \n",
       "1943438                                 0                      1   \n",
       "\n",
       "         bacno_cano_conam_mean_1h  bacno_cano_count_sum_1h  \\\n",
       "1943429                815.080000                      1.0   \n",
       "1943430                750.240000                      1.0   \n",
       "1943431                841.640000                      1.0   \n",
       "1943432                381.650000                      1.0   \n",
       "1943433                366.380000                      1.0   \n",
       "1943434               1119.110000                      1.0   \n",
       "1943435               1334.910000                      1.0   \n",
       "1943436               1230.310000                      2.0   \n",
       "1943437               1188.086667                      3.0   \n",
       "1943438               1194.660000                      1.0   \n",
       "\n",
       "         bacno_cano_conam_mean_6h  bacno_cano_count_sum_6h  \\\n",
       "1943429                815.080000                      1.0   \n",
       "1943430                750.240000                      1.0   \n",
       "1943431                841.640000                      1.0   \n",
       "1943432                611.645000                      2.0   \n",
       "1943433                366.380000                      1.0   \n",
       "1943434               1119.110000                      1.0   \n",
       "1943435               1227.010000                      2.0   \n",
       "1943436               1193.243333                      3.0   \n",
       "1943437               1170.842500                      4.0   \n",
       "1943438               1194.660000                      1.0   \n",
       "\n",
       "         bacno_cano_conam_mean_1d  bacno_cano_count_sum_1d  \\\n",
       "1943429                815.080000                      1.0   \n",
       "1943430                750.240000                      1.0   \n",
       "1943431                795.940000                      2.0   \n",
       "1943432                657.843333                      3.0   \n",
       "1943433                374.015000                      2.0   \n",
       "1943434               1119.110000                      1.0   \n",
       "1943435               1227.010000                      2.0   \n",
       "1943436               1193.243333                      3.0   \n",
       "1943437               1170.842500                      4.0   \n",
       "1943438               1194.660000                      1.0   \n",
       "\n",
       "         bacno_cano_conam_mean_30d  bacno_cano_count_sum_30d  \\\n",
       "1943429                 619.404000                      10.0   \n",
       "1943430                 657.790000                      10.0   \n",
       "1943431                 674.503636                      11.0   \n",
       "1943432                 650.099167                      12.0   \n",
       "1943433                 623.760000                      12.0   \n",
       "1943434                 661.863846                      13.0   \n",
       "1943435                 709.938571                      14.0   \n",
       "1943436                 737.656667                      15.0   \n",
       "1943437                 760.530625                      16.0   \n",
       "1943438                 803.008667                      15.0   \n",
       "\n",
       "         bacno_cano_conam_mean_7d  bacno_cano_count_sum_7d  \\\n",
       "1943429                782.833333                      3.0   \n",
       "1943430                774.685000                      4.0   \n",
       "1943431                788.076000                      5.0   \n",
       "1943432                720.338333                      6.0   \n",
       "1943433                669.772857                      7.0   \n",
       "1943434                780.080000                      7.0   \n",
       "1943435                801.287143                      7.0   \n",
       "1943436                841.840000                      8.0   \n",
       "1943437                870.928889                      9.0   \n",
       "1943438               1194.660000                      1.0   \n",
       "\n",
       "         bacno_cano_conam_mean_120d  bacno_cano_count_sum_120d  \\\n",
       "1943429                  788.288235                       17.0   \n",
       "1943430                  786.174444                       18.0   \n",
       "1943431                  789.093684                       19.0   \n",
       "1943432                  768.721500                       20.0   \n",
       "1943433                  749.562381                       21.0   \n",
       "1943434                  766.360000                       22.0   \n",
       "1943435                  791.079565                       23.0   \n",
       "1943436                  805.022500                       24.0   \n",
       "1943437                  816.967200                       25.0   \n",
       "1943438                  831.493846                       26.0   \n",
       "\n",
       "         bacno_cano_conam_mean_1h_xg_conam  bacno_cano_conam_mean_6h_xg_conam  \\\n",
       "1943429                      -2.273737e-13                      -2.273737e-13   \n",
       "1943430                      -2.273737e-13                      -2.273737e-13   \n",
       "1943431                      -2.273737e-13                      -2.273737e-13   \n",
       "1943432                      -2.273737e-13                      -2.299950e+02   \n",
       "1943433                      -2.273737e-13                      -2.273737e-13   \n",
       "1943434                      -2.273737e-13                      -2.273737e-13   \n",
       "1943435                      -2.273737e-13                       1.079000e+02   \n",
       "1943436                      -1.046000e+02                      -6.753333e+01   \n",
       "1943437                      -8.444667e+01                      -6.720250e+01   \n",
       "1943438                      -2.273737e-13                      -1.136868e-12   \n",
       "\n",
       "         bacno_cano_conam_mean_1d_xg_conam  bacno_cano_conam_mean_7d_xg_conam  \\\n",
       "1943429                      -2.273737e-13                       3.224667e+01   \n",
       "1943430                      -2.273737e-13                      -2.444500e+01   \n",
       "1943431                       4.570000e+01                       5.356400e+01   \n",
       "1943432                      -2.761933e+02                      -3.386883e+02   \n",
       "1943433                      -7.635000e+00                      -3.033929e+02   \n",
       "1943434                      -2.273737e-13                       3.390300e+02   \n",
       "1943435                       1.079000e+02                       5.336229e+02   \n",
       "1943436                      -6.753333e+01                       2.838700e+02   \n",
       "1943437                      -6.720250e+01                       2.327111e+02   \n",
       "1943438                      -1.136868e-12                      -2.273737e-13   \n",
       "\n",
       "         bacno_cano_conam_mean_30d_xg_conam  \\\n",
       "1943429                          195.676000   \n",
       "1943430                           92.450000   \n",
       "1943431                          167.136364   \n",
       "1943432                         -268.449167   \n",
       "1943433                         -257.380000   \n",
       "1943434                          457.246154   \n",
       "1943435                          624.971429   \n",
       "1943436                          388.053333   \n",
       "1943437                          343.109375   \n",
       "1943438                          391.651333   \n",
       "\n",
       "         bacno_cano_conam_mean_120d_xg_conam  bacno_cano_count_sum_7d_xg_1h  \\\n",
       "1943429                            26.791765                            2.0   \n",
       "1943430                           -35.934444                            3.0   \n",
       "1943431                            52.546316                            4.0   \n",
       "1943432                          -387.071500                            5.0   \n",
       "1943433                          -383.182381                            6.0   \n",
       "1943434                           352.750000                            6.0   \n",
       "1943435                           543.830435                            6.0   \n",
       "1943436                           320.687500                            6.0   \n",
       "1943437                           286.672800                            6.0   \n",
       "1943438                           363.166154                            0.0   \n",
       "\n",
       "         bacno_cano_count_sum_1d_xg_1h  bacno_cano_count_sum_6h_xg_1h  \\\n",
       "1943429                            0.0                            0.0   \n",
       "1943430                            0.0                            0.0   \n",
       "1943431                            1.0                            0.0   \n",
       "1943432                            2.0                            1.0   \n",
       "1943433                            1.0                            0.0   \n",
       "1943434                            0.0                            0.0   \n",
       "1943435                            1.0                            1.0   \n",
       "1943436                            1.0                            1.0   \n",
       "1943437                            1.0                            1.0   \n",
       "1943438                            0.0                            0.0   \n",
       "\n",
       "         bacno_cano_conam_mean_1h_div_conam  \\\n",
       "1943429                            1.000000   \n",
       "1943430                            1.000000   \n",
       "1943431                            1.000000   \n",
       "1943432                            1.000000   \n",
       "1943433                            1.000000   \n",
       "1943434                            1.000000   \n",
       "1943435                            1.000000   \n",
       "1943436                            0.914981   \n",
       "1943437                            0.928922   \n",
       "1943438                            1.000000   \n",
       "\n",
       "         bacno_cano_conam_mean_6h_div_conam  \\\n",
       "1943429                            1.000000   \n",
       "1943430                            1.000000   \n",
       "1943431                            1.000000   \n",
       "1943432                            0.623973   \n",
       "1943433                            1.000000   \n",
       "1943434                            1.000000   \n",
       "1943435                            1.087937   \n",
       "1943436                            0.943404   \n",
       "1943437                            0.942603   \n",
       "1943438                            1.000000   \n",
       "\n",
       "         bacno_cano_conam_mean_1d_div_conam  \\\n",
       "1943429                            1.000000   \n",
       "1943430                            1.000000   \n",
       "1943431                            1.057416   \n",
       "1943432                            0.580153   \n",
       "1943433                            0.979586   \n",
       "1943434                            1.000000   \n",
       "1943435                            1.087937   \n",
       "1943436                            0.943404   \n",
       "1943437                            0.942603   \n",
       "1943438                            1.000000   \n",
       "\n",
       "         bacno_cano_conam_mean_7d_div_conam  \\\n",
       "1943429                            1.041192   \n",
       "1943430                            0.968445   \n",
       "1943431                            1.067968   \n",
       "1943432                            0.529820   \n",
       "1943433                            0.547021   \n",
       "1943434                            1.434609   \n",
       "1943435                            1.665957   \n",
       "1943436                            1.337202   \n",
       "1943437                            1.267199   \n",
       "1943438                            1.000000   \n",
       "\n",
       "         bacno_cano_conam_mean_30d_div_conam  \\\n",
       "1943429                             1.315910   \n",
       "1943430                             1.140546   \n",
       "1943431                             1.247792   \n",
       "1943432                             0.587064   \n",
       "1943433                             0.587373   \n",
       "1943434                             1.690846   \n",
       "1943435                             1.880318   \n",
       "1943436                             1.526062   \n",
       "1943437                             1.451145   \n",
       "1943438                             1.487730   \n",
       "\n",
       "         bacno_cano_conam_mean_120d_div_conam  cano_mhcno_conam_mean_1h  \\\n",
       "1943429                              1.033987                815.080000   \n",
       "1943430                              0.954292                750.240000   \n",
       "1943431                              1.066591                841.640000   \n",
       "1943432                              0.496474                381.650000   \n",
       "1943433                              0.488792                366.380000   \n",
       "1943434                              1.460293               1119.110000   \n",
       "1943435                              1.687454               1334.910000   \n",
       "1943436                              1.398358               1230.310000   \n",
       "1943437                              1.350899               1188.086667   \n",
       "1943438                              1.436763               1194.660000   \n",
       "\n",
       "         cano_mhcno_count_sum_1h  cano_mhcno_conam_mean_6h  \\\n",
       "1943429                      1.0                815.080000   \n",
       "1943430                      1.0                750.240000   \n",
       "1943431                      1.0                841.640000   \n",
       "1943432                      1.0                381.650000   \n",
       "1943433                      1.0                366.380000   \n",
       "1943434                      1.0               1119.110000   \n",
       "1943435                      1.0               1334.910000   \n",
       "1943436                      2.0               1230.310000   \n",
       "1943437                      3.0               1188.086667   \n",
       "1943438                      1.0               1194.660000   \n",
       "\n",
       "         cano_mhcno_count_sum_6h  cano_mhcno_conam_mean_1d  \\\n",
       "1943429                      1.0                815.080000   \n",
       "1943430                      1.0                750.240000   \n",
       "1943431                      1.0                841.640000   \n",
       "1943432                      1.0                381.650000   \n",
       "1943433                      1.0                366.380000   \n",
       "1943434                      1.0               1119.110000   \n",
       "1943435                      1.0               1334.910000   \n",
       "1943436                      2.0               1230.310000   \n",
       "1943437                      3.0               1188.086667   \n",
       "1943438                      1.0               1194.660000   \n",
       "\n",
       "         cano_mhcno_count_sum_1d  cano_mhcno_conam_mean_7d  \\\n",
       "1943429                      1.0                815.080000   \n",
       "1943430                      1.0                750.240000   \n",
       "1943431                      1.0                841.640000   \n",
       "1943432                      1.0                381.650000   \n",
       "1943433                      1.0                366.380000   \n",
       "1943434                      1.0               1119.110000   \n",
       "1943435                      1.0               1334.910000   \n",
       "1943436                      2.0               1230.310000   \n",
       "1943437                      3.0               1188.086667   \n",
       "1943438                      1.0               1194.660000   \n",
       "\n",
       "         cano_mhcno_count_sum_7d  cano_mhcno_conam_mean_30d  \\\n",
       "1943429                      1.0                 815.080000   \n",
       "1943430                      1.0                 750.240000   \n",
       "1943431                      1.0                 841.640000   \n",
       "1943432                      1.0                 381.650000   \n",
       "1943433                      1.0                 366.380000   \n",
       "1943434                      1.0                1119.110000   \n",
       "1943435                      1.0                1334.910000   \n",
       "1943436                      2.0                1230.310000   \n",
       "1943437                      3.0                1188.086667   \n",
       "1943438                      1.0                1194.660000   \n",
       "\n",
       "         cano_mhcno_count_sum_30d  cano_mhcno_conam_mean_120d  \\\n",
       "1943429                       1.0                  815.080000   \n",
       "1943430                       1.0                  750.240000   \n",
       "1943431                       1.0                  841.640000   \n",
       "1943432                       1.0                  381.650000   \n",
       "1943433                       1.0                  366.380000   \n",
       "1943434                       1.0                 1119.110000   \n",
       "1943435                       1.0                 1334.910000   \n",
       "1943436                       2.0                 1230.310000   \n",
       "1943437                       3.0                 1188.086667   \n",
       "1943438                       1.0                 1194.660000   \n",
       "\n",
       "         cano_mhcno_count_sum_120d  cano_mchno_conam_mean_1h_xg_conam  \\\n",
       "1943429                        1.0                           0.000000   \n",
       "1943430                        1.0                           0.000000   \n",
       "1943431                        1.0                           0.000000   \n",
       "1943432                        1.0                           0.000000   \n",
       "1943433                        1.0                           0.000000   \n",
       "1943434                        1.0                           0.000000   \n",
       "1943435                        1.0                           0.000000   \n",
       "1943436                        2.0                        -104.600000   \n",
       "1943437                        3.0                         -84.446667   \n",
       "1943438                        1.0                           0.000000   \n",
       "\n",
       "         cano_mchno_conam_mean_6h_xg_conam  cano_mchno_conam_mean_1d_xg_conam  \\\n",
       "1943429                           0.000000                           0.000000   \n",
       "1943430                           0.000000                           0.000000   \n",
       "1943431                           0.000000                           0.000000   \n",
       "1943432                           0.000000                           0.000000   \n",
       "1943433                           0.000000                           0.000000   \n",
       "1943434                           0.000000                           0.000000   \n",
       "1943435                           0.000000                           0.000000   \n",
       "1943436                        -104.600000                        -104.600000   \n",
       "1943437                         -84.446667                         -84.446667   \n",
       "1943438                           0.000000                           0.000000   \n",
       "\n",
       "         cano_mchno_conam_mean_7d_xg_conam  \\\n",
       "1943429                           0.000000   \n",
       "1943430                           0.000000   \n",
       "1943431                           0.000000   \n",
       "1943432                           0.000000   \n",
       "1943433                           0.000000   \n",
       "1943434                           0.000000   \n",
       "1943435                           0.000000   \n",
       "1943436                        -104.600000   \n",
       "1943437                         -84.446667   \n",
       "1943438                           0.000000   \n",
       "\n",
       "         cano_mchno_conam_mean_30d_xg_conam  \\\n",
       "1943429                            0.000000   \n",
       "1943430                            0.000000   \n",
       "1943431                            0.000000   \n",
       "1943432                            0.000000   \n",
       "1943433                            0.000000   \n",
       "1943434                            0.000000   \n",
       "1943435                            0.000000   \n",
       "1943436                         -104.600000   \n",
       "1943437                          -84.446667   \n",
       "1943438                            0.000000   \n",
       "\n",
       "         cano_mchno_conam_mean_120d_xg_conam  cano_mhcno_count_sum_7d_xg_1h  \\\n",
       "1943429                             0.000000                            0.0   \n",
       "1943430                             0.000000                            0.0   \n",
       "1943431                             0.000000                            0.0   \n",
       "1943432                             0.000000                            0.0   \n",
       "1943433                             0.000000                            0.0   \n",
       "1943434                             0.000000                            0.0   \n",
       "1943435                             0.000000                            0.0   \n",
       "1943436                          -104.600000                            0.0   \n",
       "1943437                           -84.446667                            0.0   \n",
       "1943438                             0.000000                            0.0   \n",
       "\n",
       "         cano_mhcno_count_sum_1d_xg_1h  cano_mhcno_count_sum_6h_xg_1h  \\\n",
       "1943429                            0.0                            0.0   \n",
       "1943430                            0.0                            0.0   \n",
       "1943431                            0.0                            0.0   \n",
       "1943432                            0.0                            0.0   \n",
       "1943433                            0.0                            0.0   \n",
       "1943434                            0.0                            0.0   \n",
       "1943435                            0.0                            0.0   \n",
       "1943436                            0.0                            0.0   \n",
       "1943437                            0.0                            0.0   \n",
       "1943438                            0.0                            0.0   \n",
       "\n",
       "         cano_mhcno_conam_mean_1h_div_conam  \\\n",
       "1943429                            1.000000   \n",
       "1943430                            1.000000   \n",
       "1943431                            1.000000   \n",
       "1943432                            1.000000   \n",
       "1943433                            1.000000   \n",
       "1943434                            1.000000   \n",
       "1943435                            1.000000   \n",
       "1943436                            0.914981   \n",
       "1943437                            0.928922   \n",
       "1943438                            1.000000   \n",
       "\n",
       "         cano_mhcno_conam_mean_6h_div_conam  \\\n",
       "1943429                            1.000000   \n",
       "1943430                            1.000000   \n",
       "1943431                            1.000000   \n",
       "1943432                            1.000000   \n",
       "1943433                            1.000000   \n",
       "1943434                            1.000000   \n",
       "1943435                            1.000000   \n",
       "1943436                            0.914981   \n",
       "1943437                            0.928922   \n",
       "1943438                            1.000000   \n",
       "\n",
       "         cano_mhcno_conam_mean_1d_div_conam  \\\n",
       "1943429                            1.000000   \n",
       "1943430                            1.000000   \n",
       "1943431                            1.000000   \n",
       "1943432                            1.000000   \n",
       "1943433                            1.000000   \n",
       "1943434                            1.000000   \n",
       "1943435                            1.000000   \n",
       "1943436                            0.914981   \n",
       "1943437                            0.928922   \n",
       "1943438                            1.000000   \n",
       "\n",
       "         cano_mhcno_conam_mean_7d_div_conam  \\\n",
       "1943429                            1.000000   \n",
       "1943430                            1.000000   \n",
       "1943431                            1.000000   \n",
       "1943432                            1.000000   \n",
       "1943433                            1.000000   \n",
       "1943434                            1.000000   \n",
       "1943435                            1.000000   \n",
       "1943436                            0.914981   \n",
       "1943437                            0.928922   \n",
       "1943438                            1.000000   \n",
       "\n",
       "         cano_mhcno_conam_mean_30d_div_conam  \\\n",
       "1943429                             1.000000   \n",
       "1943430                             1.000000   \n",
       "1943431                             1.000000   \n",
       "1943432                             1.000000   \n",
       "1943433                             1.000000   \n",
       "1943434                             1.000000   \n",
       "1943435                             1.000000   \n",
       "1943436                             0.914981   \n",
       "1943437                             0.928922   \n",
       "1943438                             1.000000   \n",
       "\n",
       "         cano_mhcno_conam_mean_120d_div_conam  bacno_cano_stocn_unique_2d  \\\n",
       "1943429                              1.000000                         1.0   \n",
       "1943430                              1.000000                         1.0   \n",
       "1943431                              1.000000                         1.0   \n",
       "1943432                              1.000000                         1.0   \n",
       "1943433                              1.000000                         1.0   \n",
       "1943434                              1.000000                         1.0   \n",
       "1943435                              1.000000                         1.0   \n",
       "1943436                              0.914981                         1.0   \n",
       "1943437                              0.928922                         1.0   \n",
       "1943438                              1.000000                         1.0   \n",
       "\n",
       "         bacno_cano_stocn_unique_6h  bacno_cano_mchno_unique_2d  \\\n",
       "1943429                         1.0                         2.0   \n",
       "1943430                         1.0                         2.0   \n",
       "1943431                         1.0                         3.0   \n",
       "1943432                         1.0                         3.0   \n",
       "1943433                         1.0                         4.0   \n",
       "1943434                         1.0                         1.0   \n",
       "1943435                         1.0                         2.0   \n",
       "1943436                         1.0                         2.0   \n",
       "1943437                         1.0                         2.0   \n",
       "1943438                         1.0                         1.0   \n",
       "\n",
       "         bacno_cano_mchno_unique_6h  bacno_cano_mcc_unique_2d  \\\n",
       "1943429                         1.0                       2.0   \n",
       "1943430                         1.0                       2.0   \n",
       "1943431                         1.0                       3.0   \n",
       "1943432                         2.0                       3.0   \n",
       "1943433                         1.0                       4.0   \n",
       "1943434                         1.0                       1.0   \n",
       "1943435                         2.0                       2.0   \n",
       "1943436                         2.0                       2.0   \n",
       "1943437                         2.0                       2.0   \n",
       "1943438                         1.0                       1.0   \n",
       "\n",
       "         bacno_cano_mcc_unique_6h  \n",
       "1943429                       1.0  \n",
       "1943430                       1.0  \n",
       "1943431                       1.0  \n",
       "1943432                       2.0  \n",
       "1943433                       1.0  \n",
       "1943434                       1.0  \n",
       "1943435                       2.0  \n",
       "1943436                       2.0  \n",
       "1943437                       2.0  \n",
       "1943438                       1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = preprocess_train_test_split(df, raw_categorial_features)# Replace the value of categorical features of training\n",
    "                                                                                #set with NA \n",
    "                                                                                #if the value is not in testing set\n",
    "input_features = base_features \n",
    "X_train, y_train, groups, X_test = generate_X_y(df_train, df_test, label, input_features)\n",
    "X_train.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Fold 1,Train shape: (1521787, 93), test shape: (421665, 93)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's Averge Precision: 0.800959\tvalid_1's Averge Precision: 0.647371\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-33dc41c5d397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m oof_preds_LGBM, df_sub_preds_LGBM, clf = lgbm.run(X_train, y_train, groups, X_test,\n\u001b[0;32m      3\u001b[0m                                                 \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlgbm_averge_precision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                                                  ,  model_name='base_model')\n\u001b[0m",
      "\u001b[1;32m~\\Tim\\kaggle\\玉山偵測比賽\\重新來過\\TBrain_Credit_Card-master\\model\\lgbm_model.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, y, groups, test, eval_metric, n_splits, early_stopping_rounds, model_name)\u001b[0m\n\u001b[0;32m     65\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                     \u001b[0mcategorical_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m                     )\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TK2\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    803\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    806\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TK2\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    598\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TK2\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TK2\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgbm = LGBM_Model(input_features) #等這跑完\n",
    "oof_preds_LGBM, df_sub_preds_LGBM, clf = lgbm.run(X_train, y_train, groups, X_test,\n",
    "                                                lgbm.lgbm_averge_precision, n_splits = 10\n",
    "                                                 ,  model_name='base_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_sub_preds_statistics = generate_statistic(df_sub_preds_LGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Outier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some of the predictions above are very extreme, i drop it if the prediction is out of 1 standard deviation boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_preds_statistics['mean_remove_outlier'] = df_sub_preds_statistics.apply(remove_outlier, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_train['oof_base_model'] = oof_preds_LGBM\n",
    "df_test.reset_index(drop=True,inplace=True)\n",
    "df_test['sub_base_model'] = df_sub_preds_statistics['mean_remove_outlier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Model - Whitelist of Merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = base_features + [special_feautures[0]] #\n",
    "X_train, y_train, groups, X_test = generate_X_y(df_train, df_test, label, input_features)\n",
    "X_train['mchno_in_normal_mchno_list'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Fold 1,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.822541\tvalid_1's Averge Precision: 0.708602\n",
      "[200]\ttraining's Averge Precision: 0.86193\tvalid_1's Averge Precision: 0.727492\n",
      "[300]\ttraining's Averge Precision: 0.886318\tvalid_1's Averge Precision: 0.736274\n",
      "[400]\ttraining's Averge Precision: 0.903138\tvalid_1's Averge Precision: 0.741672\n",
      "[500]\ttraining's Averge Precision: 0.915386\tvalid_1's Averge Precision: 0.744526\n",
      "[600]\ttraining's Averge Precision: 0.924736\tvalid_1's Averge Precision: 0.746202\n",
      "[700]\ttraining's Averge Precision: 0.932667\tvalid_1's Averge Precision: 0.746335\n",
      "[800]\ttraining's Averge Precision: 0.939236\tvalid_1's Averge Precision: 0.747505\n",
      "[900]\ttraining's Averge Precision: 0.944812\tvalid_1's Averge Precision: 0.74673\n",
      "Early stopping, best iteration is:\n",
      "[802]\ttraining's Averge Precision: 0.93936\tvalid_1's Averge Precision: 0.74756\n",
      "Starting LightGBM. Fold 2,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.823971\tvalid_1's Averge Precision: 0.763664\n",
      "[200]\ttraining's Averge Precision: 0.863968\tvalid_1's Averge Precision: 0.782031\n",
      "[300]\ttraining's Averge Precision: 0.887588\tvalid_1's Averge Precision: 0.791551\n",
      "[400]\ttraining's Averge Precision: 0.902831\tvalid_1's Averge Precision: 0.792444\n",
      "[500]\ttraining's Averge Precision: 0.915295\tvalid_1's Averge Precision: 0.794473\n",
      "[600]\ttraining's Averge Precision: 0.924498\tvalid_1's Averge Precision: 0.794963\n",
      "Early stopping, best iteration is:\n",
      "[552]\ttraining's Averge Precision: 0.920605\tvalid_1's Averge Precision: 0.795549\n",
      "Starting LightGBM. Fold 3,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.821933\tvalid_1's Averge Precision: 0.715429\n",
      "[200]\ttraining's Averge Precision: 0.864062\tvalid_1's Averge Precision: 0.748412\n",
      "[300]\ttraining's Averge Precision: 0.888175\tvalid_1's Averge Precision: 0.760601\n",
      "[400]\ttraining's Averge Precision: 0.903465\tvalid_1's Averge Precision: 0.764655\n",
      "[500]\ttraining's Averge Precision: 0.915448\tvalid_1's Averge Precision: 0.767774\n",
      "[600]\ttraining's Averge Precision: 0.925129\tvalid_1's Averge Precision: 0.771273\n",
      "[700]\ttraining's Averge Precision: 0.932321\tvalid_1's Averge Precision: 0.773575\n",
      "[800]\ttraining's Averge Precision: 0.938631\tvalid_1's Averge Precision: 0.774942\n",
      "[900]\ttraining's Averge Precision: 0.944018\tvalid_1's Averge Precision: 0.775664\n",
      "[1000]\ttraining's Averge Precision: 0.94861\tvalid_1's Averge Precision: 0.777278\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.94861\tvalid_1's Averge Precision: 0.777278\n",
      "Starting LightGBM. Fold 4,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.822184\tvalid_1's Averge Precision: 0.73986\n",
      "[200]\ttraining's Averge Precision: 0.861933\tvalid_1's Averge Precision: 0.76048\n",
      "[300]\ttraining's Averge Precision: 0.884433\tvalid_1's Averge Precision: 0.765312\n",
      "[400]\ttraining's Averge Precision: 0.899862\tvalid_1's Averge Precision: 0.769173\n",
      "[500]\ttraining's Averge Precision: 0.912691\tvalid_1's Averge Precision: 0.771821\n",
      "[600]\ttraining's Averge Precision: 0.923004\tvalid_1's Averge Precision: 0.77343\n",
      "Early stopping, best iteration is:\n",
      "[589]\ttraining's Averge Precision: 0.92208\tvalid_1's Averge Precision: 0.773731\n",
      "Starting LightGBM. Fold 5,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.822703\tvalid_1's Averge Precision: 0.744844\n",
      "[200]\ttraining's Averge Precision: 0.863305\tvalid_1's Averge Precision: 0.765377\n",
      "[300]\ttraining's Averge Precision: 0.885543\tvalid_1's Averge Precision: 0.778273\n",
      "[400]\ttraining's Averge Precision: 0.900703\tvalid_1's Averge Precision: 0.785715\n",
      "[500]\ttraining's Averge Precision: 0.912425\tvalid_1's Averge Precision: 0.790432\n",
      "[600]\ttraining's Averge Precision: 0.922297\tvalid_1's Averge Precision: 0.793696\n",
      "[700]\ttraining's Averge Precision: 0.930087\tvalid_1's Averge Precision: 0.795415\n",
      "[800]\ttraining's Averge Precision: 0.936808\tvalid_1's Averge Precision: 0.795361\n",
      "Early stopping, best iteration is:\n",
      "[740]\ttraining's Averge Precision: 0.932834\tvalid_1's Averge Precision: 0.795758\n",
      "Starting LightGBM. Fold 6,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.826512\tvalid_1's Averge Precision: 0.76615\n",
      "[200]\ttraining's Averge Precision: 0.866223\tvalid_1's Averge Precision: 0.79005\n",
      "[300]\ttraining's Averge Precision: 0.887203\tvalid_1's Averge Precision: 0.797379\n",
      "[400]\ttraining's Averge Precision: 0.902773\tvalid_1's Averge Precision: 0.803287\n",
      "[500]\ttraining's Averge Precision: 0.915593\tvalid_1's Averge Precision: 0.808404\n",
      "[600]\ttraining's Averge Precision: 0.925011\tvalid_1's Averge Precision: 0.81064\n",
      "[700]\ttraining's Averge Precision: 0.932587\tvalid_1's Averge Precision: 0.812467\n",
      "[800]\ttraining's Averge Precision: 0.93874\tvalid_1's Averge Precision: 0.812669\n",
      "[900]\ttraining's Averge Precision: 0.944139\tvalid_1's Averge Precision: 0.81254\n",
      "Early stopping, best iteration is:\n",
      "[819]\ttraining's Averge Precision: 0.93984\tvalid_1's Averge Precision: 0.812795\n",
      "Starting LightGBM. Fold 7,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.823899\tvalid_1's Averge Precision: 0.736447\n",
      "[200]\ttraining's Averge Precision: 0.863065\tvalid_1's Averge Precision: 0.755059\n",
      "[300]\ttraining's Averge Precision: 0.885744\tvalid_1's Averge Precision: 0.764766\n",
      "[400]\ttraining's Averge Precision: 0.902332\tvalid_1's Averge Precision: 0.772785\n",
      "[500]\ttraining's Averge Precision: 0.914303\tvalid_1's Averge Precision: 0.776404\n",
      "[600]\ttraining's Averge Precision: 0.923559\tvalid_1's Averge Precision: 0.779014\n",
      "[700]\ttraining's Averge Precision: 0.931225\tvalid_1's Averge Precision: 0.779982\n",
      "[800]\ttraining's Averge Precision: 0.937726\tvalid_1's Averge Precision: 0.782238\n",
      "[900]\ttraining's Averge Precision: 0.943066\tvalid_1's Averge Precision: 0.782989\n",
      "[1000]\ttraining's Averge Precision: 0.947553\tvalid_1's Averge Precision: 0.783944\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.947553\tvalid_1's Averge Precision: 0.783944\n",
      "Starting LightGBM. Fold 8,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.819888\tvalid_1's Averge Precision: 0.772062\n",
      "[200]\ttraining's Averge Precision: 0.86223\tvalid_1's Averge Precision: 0.789086\n",
      "[300]\ttraining's Averge Precision: 0.885567\tvalid_1's Averge Precision: 0.797739\n",
      "[400]\ttraining's Averge Precision: 0.901819\tvalid_1's Averge Precision: 0.803736\n",
      "[500]\ttraining's Averge Precision: 0.913821\tvalid_1's Averge Precision: 0.807838\n",
      "[600]\ttraining's Averge Precision: 0.923904\tvalid_1's Averge Precision: 0.811169\n",
      "[700]\ttraining's Averge Precision: 0.931392\tvalid_1's Averge Precision: 0.811505\n",
      "[800]\ttraining's Averge Precision: 0.937695\tvalid_1's Averge Precision: 0.813257\n",
      "[900]\ttraining's Averge Precision: 0.942926\tvalid_1's Averge Precision: 0.813965\n",
      "[1000]\ttraining's Averge Precision: 0.947693\tvalid_1's Averge Precision: 0.814728\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.947693\tvalid_1's Averge Precision: 0.814728\n",
      "Starting LightGBM. Fold 9,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.821271\tvalid_1's Averge Precision: 0.704946\n",
      "[200]\ttraining's Averge Precision: 0.861509\tvalid_1's Averge Precision: 0.721073\n",
      "[300]\ttraining's Averge Precision: 0.883698\tvalid_1's Averge Precision: 0.729558\n",
      "[400]\ttraining's Averge Precision: 0.899985\tvalid_1's Averge Precision: 0.738091\n",
      "[500]\ttraining's Averge Precision: 0.911884\tvalid_1's Averge Precision: 0.743093\n",
      "[600]\ttraining's Averge Precision: 0.920758\tvalid_1's Averge Precision: 0.744445\n",
      "[700]\ttraining's Averge Precision: 0.928691\tvalid_1's Averge Precision: 0.745088\n",
      "[800]\ttraining's Averge Precision: 0.935459\tvalid_1's Averge Precision: 0.747338\n",
      "[900]\ttraining's Averge Precision: 0.941502\tvalid_1's Averge Precision: 0.747656\n",
      "[1000]\ttraining's Averge Precision: 0.946372\tvalid_1's Averge Precision: 0.74883\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.946372\tvalid_1's Averge Precision: 0.74883\n",
      "Starting LightGBM. Fold 10,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.826004\tvalid_1's Averge Precision: 0.717708\n",
      "[200]\ttraining's Averge Precision: 0.8669\tvalid_1's Averge Precision: 0.736239\n",
      "[300]\ttraining's Averge Precision: 0.890391\tvalid_1's Averge Precision: 0.747189\n",
      "[400]\ttraining's Averge Precision: 0.905617\tvalid_1's Averge Precision: 0.749281\n",
      "[500]\ttraining's Averge Precision: 0.916556\tvalid_1's Averge Precision: 0.751522\n",
      "[600]\ttraining's Averge Precision: 0.925672\tvalid_1's Averge Precision: 0.751478\n",
      "Early stopping, best iteration is:\n",
      "[528]\ttraining's Averge Precision: 0.919749\tvalid_1's Averge Precision: 0.752033\n",
      "Summary:\n",
      "LGBM Testing_Set average_precision_score 0.777661\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBM_Model(input_features)\n",
    "oof_preds_LGBM, df_sub_preds_LGBM, clf = lgbm.run(X_train, y_train, groups, X_test, lgbm.lgbm_averge_precision, n_splits = 10 \n",
    "                                                 , model_name='Whitelist_of_Merchant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_sub_preds_statistics = generate_statistic(df_sub_preds_LGBM)\n",
    "df_sub_preds_statistics['mean_remove_outlier'] = df_sub_preds_statistics.apply(remove_outlier, axis = 1)\n",
    "df_train['oof_normal_mchno_model'] = oof_preds_LGBM\n",
    "df_test['sub_normal_mchno_model'] = df_sub_preds_statistics['mean_remove_outlier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Model - Blacklist of Merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = base_features + [special_feautures[1]]\n",
    "X_train, y_train, groups, X_test = generate_X_y(df_train, df_test, label, input_features)\n",
    "X_train['mchno_in_fraud_mchno_list'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Fold 1,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.831112\tvalid_1's Averge Precision: 0.741078\n",
      "[200]\ttraining's Averge Precision: 0.867921\tvalid_1's Averge Precision: 0.758423\n",
      "[300]\ttraining's Averge Precision: 0.888832\tvalid_1's Averge Precision: 0.76456\n",
      "[400]\ttraining's Averge Precision: 0.905362\tvalid_1's Averge Precision: 0.769277\n",
      "[500]\ttraining's Averge Precision: 0.916613\tvalid_1's Averge Precision: 0.768652\n",
      "[600]\ttraining's Averge Precision: 0.926519\tvalid_1's Averge Precision: 0.770257\n",
      "[700]\ttraining's Averge Precision: 0.933882\tvalid_1's Averge Precision: 0.770482\n",
      "[800]\ttraining's Averge Precision: 0.940261\tvalid_1's Averge Precision: 0.771231\n",
      "[900]\ttraining's Averge Precision: 0.945892\tvalid_1's Averge Precision: 0.771014\n",
      "Early stopping, best iteration is:\n",
      "[809]\ttraining's Averge Precision: 0.940858\tvalid_1's Averge Precision: 0.771697\n",
      "Starting LightGBM. Fold 2,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.831803\tvalid_1's Averge Precision: 0.757588\n",
      "[200]\ttraining's Averge Precision: 0.868811\tvalid_1's Averge Precision: 0.769869\n",
      "[300]\ttraining's Averge Precision: 0.890088\tvalid_1's Averge Precision: 0.775045\n",
      "[400]\ttraining's Averge Precision: 0.905562\tvalid_1's Averge Precision: 0.780733\n",
      "[500]\ttraining's Averge Precision: 0.916559\tvalid_1's Averge Precision: 0.779893\n",
      "Early stopping, best iteration is:\n",
      "[437]\ttraining's Averge Precision: 0.910064\tvalid_1's Averge Precision: 0.781382\n",
      "Starting LightGBM. Fold 3,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.830251\tvalid_1's Averge Precision: 0.748255\n",
      "[200]\ttraining's Averge Precision: 0.866296\tvalid_1's Averge Precision: 0.766093\n",
      "[300]\ttraining's Averge Precision: 0.887399\tvalid_1's Averge Precision: 0.773983\n",
      "[400]\ttraining's Averge Precision: 0.902849\tvalid_1's Averge Precision: 0.777589\n",
      "[500]\ttraining's Averge Precision: 0.914843\tvalid_1's Averge Precision: 0.782199\n",
      "[600]\ttraining's Averge Precision: 0.924207\tvalid_1's Averge Precision: 0.787224\n",
      "[700]\ttraining's Averge Precision: 0.932161\tvalid_1's Averge Precision: 0.789675\n",
      "[800]\ttraining's Averge Precision: 0.938649\tvalid_1's Averge Precision: 0.791553\n",
      "[900]\ttraining's Averge Precision: 0.944362\tvalid_1's Averge Precision: 0.792277\n",
      "[1000]\ttraining's Averge Precision: 0.949333\tvalid_1's Averge Precision: 0.792678\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.949333\tvalid_1's Averge Precision: 0.792678\n",
      "Starting LightGBM. Fold 4,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.836571\tvalid_1's Averge Precision: 0.758389\n",
      "[200]\ttraining's Averge Precision: 0.874061\tvalid_1's Averge Precision: 0.773525\n",
      "[300]\ttraining's Averge Precision: 0.894213\tvalid_1's Averge Precision: 0.779254\n",
      "[400]\ttraining's Averge Precision: 0.908465\tvalid_1's Averge Precision: 0.782649\n",
      "[500]\ttraining's Averge Precision: 0.920007\tvalid_1's Averge Precision: 0.784264\n",
      "Early stopping, best iteration is:\n",
      "[477]\ttraining's Averge Precision: 0.91756\tvalid_1's Averge Precision: 0.785142\n",
      "Starting LightGBM. Fold 5,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.836088\tvalid_1's Averge Precision: 0.74195\n",
      "[200]\ttraining's Averge Precision: 0.870629\tvalid_1's Averge Precision: 0.758646\n",
      "[300]\ttraining's Averge Precision: 0.890793\tvalid_1's Averge Precision: 0.772012\n",
      "[400]\ttraining's Averge Precision: 0.905622\tvalid_1's Averge Precision: 0.779613\n",
      "[500]\ttraining's Averge Precision: 0.916839\tvalid_1's Averge Precision: 0.783259\n",
      "[600]\ttraining's Averge Precision: 0.926278\tvalid_1's Averge Precision: 0.787718\n",
      "[700]\ttraining's Averge Precision: 0.933789\tvalid_1's Averge Precision: 0.788404\n",
      "[800]\ttraining's Averge Precision: 0.940137\tvalid_1's Averge Precision: 0.790638\n",
      "[900]\ttraining's Averge Precision: 0.945343\tvalid_1's Averge Precision: 0.791044\n",
      "[1000]\ttraining's Averge Precision: 0.949907\tvalid_1's Averge Precision: 0.790808\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.949907\tvalid_1's Averge Precision: 0.790808\n",
      "Starting LightGBM. Fold 6,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.832595\tvalid_1's Averge Precision: 0.775864\n",
      "[200]\ttraining's Averge Precision: 0.87042\tvalid_1's Averge Precision: 0.793689\n",
      "[300]\ttraining's Averge Precision: 0.891692\tvalid_1's Averge Precision: 0.800647\n",
      "[400]\ttraining's Averge Precision: 0.905905\tvalid_1's Averge Precision: 0.805894\n",
      "[500]\ttraining's Averge Precision: 0.917535\tvalid_1's Averge Precision: 0.809052\n",
      "[600]\ttraining's Averge Precision: 0.927214\tvalid_1's Averge Precision: 0.810489\n",
      "[700]\ttraining's Averge Precision: 0.934645\tvalid_1's Averge Precision: 0.81143\n",
      "[800]\ttraining's Averge Precision: 0.940975\tvalid_1's Averge Precision: 0.811984\n",
      "[900]\ttraining's Averge Precision: 0.946557\tvalid_1's Averge Precision: 0.811981\n",
      "Early stopping, best iteration is:\n",
      "[869]\ttraining's Averge Precision: 0.944982\tvalid_1's Averge Precision: 0.812383\n",
      "Starting LightGBM. Fold 7,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.831943\tvalid_1's Averge Precision: 0.752688\n",
      "[200]\ttraining's Averge Precision: 0.868143\tvalid_1's Averge Precision: 0.772495\n",
      "[300]\ttraining's Averge Precision: 0.89055\tvalid_1's Averge Precision: 0.783508\n",
      "[400]\ttraining's Averge Precision: 0.905097\tvalid_1's Averge Precision: 0.788687\n",
      "[500]\ttraining's Averge Precision: 0.917005\tvalid_1's Averge Precision: 0.791946\n",
      "[600]\ttraining's Averge Precision: 0.926417\tvalid_1's Averge Precision: 0.793564\n",
      "[700]\ttraining's Averge Precision: 0.934183\tvalid_1's Averge Precision: 0.794506\n",
      "Early stopping, best iteration is:\n",
      "[651]\ttraining's Averge Precision: 0.930462\tvalid_1's Averge Precision: 0.794941\n",
      "Starting LightGBM. Fold 8,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.825284\tvalid_1's Averge Precision: 0.776311\n",
      "[200]\ttraining's Averge Precision: 0.866753\tvalid_1's Averge Precision: 0.794952\n",
      "[300]\ttraining's Averge Precision: 0.887889\tvalid_1's Averge Precision: 0.802604\n",
      "[400]\ttraining's Averge Precision: 0.903015\tvalid_1's Averge Precision: 0.8086\n",
      "[500]\ttraining's Averge Precision: 0.915551\tvalid_1's Averge Precision: 0.812688\n",
      "[600]\ttraining's Averge Precision: 0.924704\tvalid_1's Averge Precision: 0.816012\n",
      "[700]\ttraining's Averge Precision: 0.932421\tvalid_1's Averge Precision: 0.817812\n",
      "[800]\ttraining's Averge Precision: 0.938919\tvalid_1's Averge Precision: 0.819157\n",
      "[900]\ttraining's Averge Precision: 0.944528\tvalid_1's Averge Precision: 0.820774\n",
      "[1000]\ttraining's Averge Precision: 0.949117\tvalid_1's Averge Precision: 0.821746\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.949117\tvalid_1's Averge Precision: 0.821746\n",
      "Starting LightGBM. Fold 9,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.830888\tvalid_1's Averge Precision: 0.727427\n",
      "[200]\ttraining's Averge Precision: 0.865677\tvalid_1's Averge Precision: 0.74086\n",
      "[300]\ttraining's Averge Precision: 0.88731\tvalid_1's Averge Precision: 0.750224\n",
      "[400]\ttraining's Averge Precision: 0.902967\tvalid_1's Averge Precision: 0.753529\n",
      "[500]\ttraining's Averge Precision: 0.915112\tvalid_1's Averge Precision: 0.75661\n",
      "[600]\ttraining's Averge Precision: 0.92445\tvalid_1's Averge Precision: 0.758653\n",
      "[700]\ttraining's Averge Precision: 0.93222\tvalid_1's Averge Precision: 0.759398\n",
      "[800]\ttraining's Averge Precision: 0.938519\tvalid_1's Averge Precision: 0.759819\n",
      "[900]\ttraining's Averge Precision: 0.943899\tvalid_1's Averge Precision: 0.76031\n",
      "[1000]\ttraining's Averge Precision: 0.948513\tvalid_1's Averge Precision: 0.759912\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.948513\tvalid_1's Averge Precision: 0.759912\n",
      "Starting LightGBM. Fold 10,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.836298\tvalid_1's Averge Precision: 0.735576\n",
      "[200]\ttraining's Averge Precision: 0.871309\tvalid_1's Averge Precision: 0.750412\n",
      "[300]\ttraining's Averge Precision: 0.892695\tvalid_1's Averge Precision: 0.757788\n",
      "[400]\ttraining's Averge Precision: 0.907749\tvalid_1's Averge Precision: 0.761118\n",
      "[500]\ttraining's Averge Precision: 0.919293\tvalid_1's Averge Precision: 0.762749\n",
      "[600]\ttraining's Averge Precision: 0.928696\tvalid_1's Averge Precision: 0.764422\n",
      "[700]\ttraining's Averge Precision: 0.935933\tvalid_1's Averge Precision: 0.765403\n",
      "[800]\ttraining's Averge Precision: 0.941916\tvalid_1's Averge Precision: 0.767094\n",
      "[900]\ttraining's Averge Precision: 0.947016\tvalid_1's Averge Precision: 0.768267\n",
      "[1000]\ttraining's Averge Precision: 0.951619\tvalid_1's Averge Precision: 0.769515\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.951619\tvalid_1's Averge Precision: 0.769515\n",
      "Summary:\n",
      "LGBM Testing_Set average_precision_score 0.785540\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBM_Model(input_features)\n",
    "oof_preds_LGBM, df_sub_preds_LGBM, clf = lgbm.run(X_train, y_train, groups, X_test, lgbm.lgbm_averge_precision, n_splits = 10\n",
    "                                                  , model_name='blacklist_of_Merchant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_sub_preds_statistics = generate_statistic(df_sub_preds_LGBM)\n",
    "df_sub_preds_statistics['mean_remove_outlier'] = df_sub_preds_statistics.apply(remove_outlier, axis = 1)\n",
    "df_train['oof_fraud_mchno_model'] = oof_preds_LGBM\n",
    "df_test['sub_fraud_mchno_model'] = df_sub_preds_statistics['mean_remove_outlier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Model - Blacklist of Transaction Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = base_features + [special_feautures[2]]\n",
    "X_train, y_train, groups, X_test = generate_X_y(df_train, df_test, label, input_features)\n",
    "X_train['conam_in_fraud_conam_list'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Fold 1,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.816676\tvalid_1's Averge Precision: 0.69224\n",
      "[200]\ttraining's Averge Precision: 0.856489\tvalid_1's Averge Precision: 0.708883\n",
      "[300]\ttraining's Averge Precision: 0.87841\tvalid_1's Averge Precision: 0.7144\n",
      "[400]\ttraining's Averge Precision: 0.895186\tvalid_1's Averge Precision: 0.71769\n",
      "[500]\ttraining's Averge Precision: 0.908079\tvalid_1's Averge Precision: 0.719589\n",
      "[600]\ttraining's Averge Precision: 0.917924\tvalid_1's Averge Precision: 0.719857\n",
      "Early stopping, best iteration is:\n",
      "[531]\ttraining's Averge Precision: 0.911371\tvalid_1's Averge Precision: 0.72022\n",
      "Starting LightGBM. Fold 2,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.818198\tvalid_1's Averge Precision: 0.728444\n",
      "[200]\ttraining's Averge Precision: 0.857641\tvalid_1's Averge Precision: 0.745414\n",
      "[300]\ttraining's Averge Precision: 0.880232\tvalid_1's Averge Precision: 0.752887\n",
      "[400]\ttraining's Averge Precision: 0.896336\tvalid_1's Averge Precision: 0.755704\n",
      "[500]\ttraining's Averge Precision: 0.908406\tvalid_1's Averge Precision: 0.756606\n",
      "[600]\ttraining's Averge Precision: 0.918867\tvalid_1's Averge Precision: 0.757623\n",
      "[700]\ttraining's Averge Precision: 0.927223\tvalid_1's Averge Precision: 0.759454\n",
      "Early stopping, best iteration is:\n",
      "[691]\ttraining's Averge Precision: 0.926507\tvalid_1's Averge Precision: 0.75988\n",
      "Starting LightGBM. Fold 3,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.814374\tvalid_1's Averge Precision: 0.724544\n",
      "[200]\ttraining's Averge Precision: 0.854045\tvalid_1's Averge Precision: 0.736584\n",
      "[300]\ttraining's Averge Precision: 0.877587\tvalid_1's Averge Precision: 0.759366\n",
      "[400]\ttraining's Averge Precision: 0.893483\tvalid_1's Averge Precision: 0.766363\n",
      "[500]\ttraining's Averge Precision: 0.90667\tvalid_1's Averge Precision: 0.77063\n",
      "[600]\ttraining's Averge Precision: 0.916516\tvalid_1's Averge Precision: 0.773307\n",
      "[700]\ttraining's Averge Precision: 0.924745\tvalid_1's Averge Precision: 0.775267\n",
      "[800]\ttraining's Averge Precision: 0.931817\tvalid_1's Averge Precision: 0.776794\n",
      "[900]\ttraining's Averge Precision: 0.937657\tvalid_1's Averge Precision: 0.778619\n",
      "[1000]\ttraining's Averge Precision: 0.942832\tvalid_1's Averge Precision: 0.779451\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.942832\tvalid_1's Averge Precision: 0.779451\n",
      "Starting LightGBM. Fold 4,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.818852\tvalid_1's Averge Precision: 0.748356\n",
      "[200]\ttraining's Averge Precision: 0.857648\tvalid_1's Averge Precision: 0.762376\n",
      "[300]\ttraining's Averge Precision: 0.879706\tvalid_1's Averge Precision: 0.767571\n",
      "[400]\ttraining's Averge Precision: 0.895262\tvalid_1's Averge Precision: 0.768137\n",
      "Early stopping, best iteration is:\n",
      "[358]\ttraining's Averge Precision: 0.88951\tvalid_1's Averge Precision: 0.769485\n",
      "Starting LightGBM. Fold 5,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.817425\tvalid_1's Averge Precision: 0.717889\n",
      "[200]\ttraining's Averge Precision: 0.855324\tvalid_1's Averge Precision: 0.742957\n",
      "[300]\ttraining's Averge Precision: 0.877249\tvalid_1's Averge Precision: 0.752446\n",
      "[400]\ttraining's Averge Precision: 0.893538\tvalid_1's Averge Precision: 0.755401\n",
      "[500]\ttraining's Averge Precision: 0.907049\tvalid_1's Averge Precision: 0.761815\n",
      "[600]\ttraining's Averge Precision: 0.917067\tvalid_1's Averge Precision: 0.76745\n",
      "[700]\ttraining's Averge Precision: 0.925347\tvalid_1's Averge Precision: 0.770816\n",
      "[800]\ttraining's Averge Precision: 0.932431\tvalid_1's Averge Precision: 0.771498\n",
      "[900]\ttraining's Averge Precision: 0.938316\tvalid_1's Averge Precision: 0.773009\n",
      "[1000]\ttraining's Averge Precision: 0.94331\tvalid_1's Averge Precision: 0.774957\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.94331\tvalid_1's Averge Precision: 0.774957\n",
      "Starting LightGBM. Fold 6,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.815591\tvalid_1's Averge Precision: 0.733456\n",
      "[200]\ttraining's Averge Precision: 0.854652\tvalid_1's Averge Precision: 0.762741\n",
      "[300]\ttraining's Averge Precision: 0.877434\tvalid_1's Averge Precision: 0.772575\n",
      "[400]\ttraining's Averge Precision: 0.893779\tvalid_1's Averge Precision: 0.777597\n",
      "[500]\ttraining's Averge Precision: 0.905954\tvalid_1's Averge Precision: 0.783121\n",
      "[600]\ttraining's Averge Precision: 0.91588\tvalid_1's Averge Precision: 0.785683\n",
      "[700]\ttraining's Averge Precision: 0.924277\tvalid_1's Averge Precision: 0.787862\n",
      "[800]\ttraining's Averge Precision: 0.931145\tvalid_1's Averge Precision: 0.789489\n",
      "[900]\ttraining's Averge Precision: 0.937574\tvalid_1's Averge Precision: 0.791677\n",
      "[1000]\ttraining's Averge Precision: 0.942987\tvalid_1's Averge Precision: 0.79229\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.942987\tvalid_1's Averge Precision: 0.79229\n",
      "Starting LightGBM. Fold 7,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.818953\tvalid_1's Averge Precision: 0.731068\n",
      "[200]\ttraining's Averge Precision: 0.856946\tvalid_1's Averge Precision: 0.750442\n",
      "[300]\ttraining's Averge Precision: 0.878442\tvalid_1's Averge Precision: 0.761181\n",
      "[400]\ttraining's Averge Precision: 0.894747\tvalid_1's Averge Precision: 0.769454\n",
      "[500]\ttraining's Averge Precision: 0.907805\tvalid_1's Averge Precision: 0.773568\n",
      "[600]\ttraining's Averge Precision: 0.917748\tvalid_1's Averge Precision: 0.776474\n",
      "[700]\ttraining's Averge Precision: 0.925602\tvalid_1's Averge Precision: 0.778296\n",
      "[800]\ttraining's Averge Precision: 0.93268\tvalid_1's Averge Precision: 0.77987\n",
      "[900]\ttraining's Averge Precision: 0.938823\tvalid_1's Averge Precision: 0.781216\n",
      "[1000]\ttraining's Averge Precision: 0.943649\tvalid_1's Averge Precision: 0.781325\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.943649\tvalid_1's Averge Precision: 0.781325\n",
      "Starting LightGBM. Fold 8,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.811113\tvalid_1's Averge Precision: 0.770387\n",
      "[200]\ttraining's Averge Precision: 0.851105\tvalid_1's Averge Precision: 0.782585\n",
      "[300]\ttraining's Averge Precision: 0.876464\tvalid_1's Averge Precision: 0.792878\n",
      "[400]\ttraining's Averge Precision: 0.892969\tvalid_1's Averge Precision: 0.798572\n",
      "[500]\ttraining's Averge Precision: 0.906107\tvalid_1's Averge Precision: 0.801678\n",
      "[600]\ttraining's Averge Precision: 0.916453\tvalid_1's Averge Precision: 0.804448\n",
      "[700]\ttraining's Averge Precision: 0.924806\tvalid_1's Averge Precision: 0.805684\n",
      "[800]\ttraining's Averge Precision: 0.931693\tvalid_1's Averge Precision: 0.806095\n",
      "Early stopping, best iteration is:\n",
      "[769]\ttraining's Averge Precision: 0.929725\tvalid_1's Averge Precision: 0.806668\n",
      "Starting LightGBM. Fold 9,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.813423\tvalid_1's Averge Precision: 0.691128\n",
      "[200]\ttraining's Averge Precision: 0.85428\tvalid_1's Averge Precision: 0.710442\n",
      "[300]\ttraining's Averge Precision: 0.877398\tvalid_1's Averge Precision: 0.713613\n",
      "[400]\ttraining's Averge Precision: 0.894397\tvalid_1's Averge Precision: 0.721527\n",
      "[500]\ttraining's Averge Precision: 0.906333\tvalid_1's Averge Precision: 0.726129\n",
      "[600]\ttraining's Averge Precision: 0.916759\tvalid_1's Averge Precision: 0.726909\n",
      "[700]\ttraining's Averge Precision: 0.925262\tvalid_1's Averge Precision: 0.727331\n",
      "[800]\ttraining's Averge Precision: 0.932236\tvalid_1's Averge Precision: 0.729287\n",
      "[900]\ttraining's Averge Precision: 0.937906\tvalid_1's Averge Precision: 0.73056\n",
      "[1000]\ttraining's Averge Precision: 0.942945\tvalid_1's Averge Precision: 0.731449\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.942945\tvalid_1's Averge Precision: 0.731449\n",
      "Starting LightGBM. Fold 10,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.818556\tvalid_1's Averge Precision: 0.7148\n",
      "[200]\ttraining's Averge Precision: 0.859015\tvalid_1's Averge Precision: 0.732209\n",
      "[300]\ttraining's Averge Precision: 0.882154\tvalid_1's Averge Precision: 0.740505\n",
      "[400]\ttraining's Averge Precision: 0.898413\tvalid_1's Averge Precision: 0.744258\n",
      "[500]\ttraining's Averge Precision: 0.910255\tvalid_1's Averge Precision: 0.746991\n",
      "[600]\ttraining's Averge Precision: 0.920024\tvalid_1's Averge Precision: 0.748013\n",
      "[700]\ttraining's Averge Precision: 0.927976\tvalid_1's Averge Precision: 0.748966\n",
      "[800]\ttraining's Averge Precision: 0.934683\tvalid_1's Averge Precision: 0.750416\n",
      "[900]\ttraining's Averge Precision: 0.940286\tvalid_1's Averge Precision: 0.752241\n",
      "[1000]\ttraining's Averge Precision: 0.945434\tvalid_1's Averge Precision: 0.752518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.945434\tvalid_1's Averge Precision: 0.752518\n",
      "Summary:\n",
      "LGBM Testing_Set average_precision_score 0.763490\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBM_Model(input_features)\n",
    "oof_preds_LGBM, df_sub_preds_LGBM, clf = lgbm.run(X_train, y_train, groups, X_test, lgbm.lgbm_averge_precision, n_splits = 10\n",
    "                                                 , model_name='Blacklist_of_Transaction_Amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_sub_preds_statistics = generate_statistic(df_sub_preds_LGBM)\n",
    "df_sub_preds_statistics['mean_remove_outlier'] = df_sub_preds_statistics.apply(remove_outlier, axis = 1)\n",
    "df_train['oof_fraud_conam_model'] = oof_preds_LGBM\n",
    "df_test['sub_fraud_conam_model'] = df_sub_preds_statistics['mean_remove_outlier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Model - Elapsed Day of First Fraudulent Transaction(if exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan,  7.,  1., 12., 11., 14.,  9.,  2.,  5.,  8., 57.,  3., 15.,\n",
       "        6., 13., 17., 18., 21., 22., 23., 30., 16., 28., 31., 41., 51.,\n",
       "       52., 71., 34.,  4., 24., 19., 26., 27., 36., 37., 33., 42., 44.,\n",
       "       45., 10., 46., 47., 56., 58., 61., 63., 29., 20., 50., 55., 38.,\n",
       "       39., 49., 70., 72., 74., 25., 43., 54., 48., 35., 32., 53., 40.,\n",
       "       62., 60., 59., 75., 64., 67., 68., 69., 73., 76., 77., 80., 81.,\n",
       "       83., 88., 65., 78., 79., 82., 87., 66., 84., 85.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = base_features + [special_feautures[3]]\n",
    "X_train, y_train, groups, X_test = generate_X_y(df_train, df_test, label, input_features)\n",
    "X_train['diff_with_first_fraud_locdt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Fold 1,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.836907\tvalid_1's Averge Precision: 0.74294\n",
      "[200]\ttraining's Averge Precision: 0.874894\tvalid_1's Averge Precision: 0.759197\n",
      "[300]\ttraining's Averge Precision: 0.894684\tvalid_1's Averge Precision: 0.763892\n",
      "[400]\ttraining's Averge Precision: 0.911028\tvalid_1's Averge Precision: 0.767644\n",
      "[500]\ttraining's Averge Precision: 0.92278\tvalid_1's Averge Precision: 0.77085\n",
      "[600]\ttraining's Averge Precision: 0.932288\tvalid_1's Averge Precision: 0.771871\n",
      "[700]\ttraining's Averge Precision: 0.939607\tvalid_1's Averge Precision: 0.77215\n",
      "Early stopping, best iteration is:\n",
      "[684]\ttraining's Averge Precision: 0.938599\tvalid_1's Averge Precision: 0.772534\n",
      "Starting LightGBM. Fold 2,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.837981\tvalid_1's Averge Precision: 0.769885\n",
      "[200]\ttraining's Averge Precision: 0.875084\tvalid_1's Averge Precision: 0.784909\n",
      "[300]\ttraining's Averge Precision: 0.897778\tvalid_1's Averge Precision: 0.790684\n",
      "[400]\ttraining's Averge Precision: 0.911683\tvalid_1's Averge Precision: 0.793335\n",
      "[500]\ttraining's Averge Precision: 0.9228\tvalid_1's Averge Precision: 0.794791\n",
      "[600]\ttraining's Averge Precision: 0.931708\tvalid_1's Averge Precision: 0.794722\n",
      "Early stopping, best iteration is:\n",
      "[589]\ttraining's Averge Precision: 0.930734\tvalid_1's Averge Precision: 0.795292\n",
      "Starting LightGBM. Fold 3,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.835248\tvalid_1's Averge Precision: 0.74483\n",
      "[200]\ttraining's Averge Precision: 0.872567\tvalid_1's Averge Precision: 0.767843\n",
      "[300]\ttraining's Averge Precision: 0.894038\tvalid_1's Averge Precision: 0.776559\n",
      "[400]\ttraining's Averge Precision: 0.909157\tvalid_1's Averge Precision: 0.785614\n",
      "[500]\ttraining's Averge Precision: 0.920212\tvalid_1's Averge Precision: 0.788229\n",
      "[600]\ttraining's Averge Precision: 0.929225\tvalid_1's Averge Precision: 0.791455\n",
      "[700]\ttraining's Averge Precision: 0.936674\tvalid_1's Averge Precision: 0.793598\n",
      "[800]\ttraining's Averge Precision: 0.942656\tvalid_1's Averge Precision: 0.795633\n",
      "[900]\ttraining's Averge Precision: 0.947763\tvalid_1's Averge Precision: 0.797766\n",
      "[1000]\ttraining's Averge Precision: 0.952084\tvalid_1's Averge Precision: 0.798182\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.952084\tvalid_1's Averge Precision: 0.798182\n",
      "Starting LightGBM. Fold 4,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.836171\tvalid_1's Averge Precision: 0.759871\n",
      "[200]\ttraining's Averge Precision: 0.875218\tvalid_1's Averge Precision: 0.77752\n",
      "[300]\ttraining's Averge Precision: 0.896448\tvalid_1's Averge Precision: 0.783049\n",
      "[400]\ttraining's Averge Precision: 0.910533\tvalid_1's Averge Precision: 0.786278\n",
      "[500]\ttraining's Averge Precision: 0.921964\tvalid_1's Averge Precision: 0.788114\n",
      "[600]\ttraining's Averge Precision: 0.931149\tvalid_1's Averge Precision: 0.789532\n",
      "Early stopping, best iteration is:\n",
      "[561]\ttraining's Averge Precision: 0.927893\tvalid_1's Averge Precision: 0.78955\n",
      "Starting LightGBM. Fold 5,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.839272\tvalid_1's Averge Precision: 0.744765\n",
      "[200]\ttraining's Averge Precision: 0.877375\tvalid_1's Averge Precision: 0.772286\n",
      "[300]\ttraining's Averge Precision: 0.896849\tvalid_1's Averge Precision: 0.782043\n",
      "[400]\ttraining's Averge Precision: 0.91176\tvalid_1's Averge Precision: 0.787243\n",
      "[500]\ttraining's Averge Precision: 0.922199\tvalid_1's Averge Precision: 0.789644\n",
      "[600]\ttraining's Averge Precision: 0.930894\tvalid_1's Averge Precision: 0.791971\n",
      "[700]\ttraining's Averge Precision: 0.938227\tvalid_1's Averge Precision: 0.797485\n",
      "[800]\ttraining's Averge Precision: 0.944439\tvalid_1's Averge Precision: 0.797537\n",
      "[900]\ttraining's Averge Precision: 0.949206\tvalid_1's Averge Precision: 0.798818\n",
      "[1000]\ttraining's Averge Precision: 0.953687\tvalid_1's Averge Precision: 0.799763\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.953687\tvalid_1's Averge Precision: 0.799763\n",
      "Starting LightGBM. Fold 6,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.836613\tvalid_1's Averge Precision: 0.766789\n",
      "[200]\ttraining's Averge Precision: 0.875277\tvalid_1's Averge Precision: 0.789209\n",
      "[300]\ttraining's Averge Precision: 0.897439\tvalid_1's Averge Precision: 0.799664\n",
      "[400]\ttraining's Averge Precision: 0.91204\tvalid_1's Averge Precision: 0.805273\n",
      "[500]\ttraining's Averge Precision: 0.92314\tvalid_1's Averge Precision: 0.810256\n",
      "[600]\ttraining's Averge Precision: 0.932201\tvalid_1's Averge Precision: 0.811474\n",
      "[700]\ttraining's Averge Precision: 0.939531\tvalid_1's Averge Precision: 0.813543\n",
      "[800]\ttraining's Averge Precision: 0.945316\tvalid_1's Averge Precision: 0.813854\n",
      "Early stopping, best iteration is:\n",
      "[729]\ttraining's Averge Precision: 0.941165\tvalid_1's Averge Precision: 0.814353\n",
      "Starting LightGBM. Fold 7,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.838488\tvalid_1's Averge Precision: 0.763729\n",
      "[200]\ttraining's Averge Precision: 0.875025\tvalid_1's Averge Precision: 0.782994\n",
      "[300]\ttraining's Averge Precision: 0.896572\tvalid_1's Averge Precision: 0.792929\n",
      "[400]\ttraining's Averge Precision: 0.911787\tvalid_1's Averge Precision: 0.798174\n",
      "[500]\ttraining's Averge Precision: 0.923252\tvalid_1's Averge Precision: 0.801588\n",
      "[600]\ttraining's Averge Precision: 0.932018\tvalid_1's Averge Precision: 0.803727\n",
      "[700]\ttraining's Averge Precision: 0.939022\tvalid_1's Averge Precision: 0.804002\n",
      "[800]\ttraining's Averge Precision: 0.94496\tvalid_1's Averge Precision: 0.805085\n",
      "[900]\ttraining's Averge Precision: 0.95012\tvalid_1's Averge Precision: 0.806397\n",
      "[1000]\ttraining's Averge Precision: 0.954311\tvalid_1's Averge Precision: 0.806388\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.954311\tvalid_1's Averge Precision: 0.806388\n",
      "Starting LightGBM. Fold 8,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.83034\tvalid_1's Averge Precision: 0.788431\n",
      "[200]\ttraining's Averge Precision: 0.872102\tvalid_1's Averge Precision: 0.802939\n",
      "[300]\ttraining's Averge Precision: 0.894341\tvalid_1's Averge Precision: 0.81127\n",
      "[400]\ttraining's Averge Precision: 0.910003\tvalid_1's Averge Precision: 0.816909\n",
      "[500]\ttraining's Averge Precision: 0.921117\tvalid_1's Averge Precision: 0.819494\n",
      "[600]\ttraining's Averge Precision: 0.930061\tvalid_1's Averge Precision: 0.822574\n",
      "[700]\ttraining's Averge Precision: 0.937434\tvalid_1's Averge Precision: 0.824943\n",
      "[800]\ttraining's Averge Precision: 0.94323\tvalid_1's Averge Precision: 0.826203\n",
      "[900]\ttraining's Averge Precision: 0.94851\tvalid_1's Averge Precision: 0.825789\n",
      "Early stopping, best iteration is:\n",
      "[803]\ttraining's Averge Precision: 0.943438\tvalid_1's Averge Precision: 0.826365\n",
      "Starting LightGBM. Fold 9,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.834549\tvalid_1's Averge Precision: 0.733447\n",
      "[200]\ttraining's Averge Precision: 0.872516\tvalid_1's Averge Precision: 0.746425\n",
      "[300]\ttraining's Averge Precision: 0.894661\tvalid_1's Averge Precision: 0.751398\n",
      "[400]\ttraining's Averge Precision: 0.909912\tvalid_1's Averge Precision: 0.756002\n",
      "[500]\ttraining's Averge Precision: 0.92113\tvalid_1's Averge Precision: 0.757833\n",
      "[600]\ttraining's Averge Precision: 0.929811\tvalid_1's Averge Precision: 0.758907\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's Averge Precision: 0.925522\tvalid_1's Averge Precision: 0.759224\n",
      "Starting LightGBM. Fold 10,Train shape: (1521787, 94), test shape: (421665, 94)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's Averge Precision: 0.838643\tvalid_1's Averge Precision: 0.730579\n",
      "[200]\ttraining's Averge Precision: 0.8782\tvalid_1's Averge Precision: 0.74785\n",
      "[300]\ttraining's Averge Precision: 0.897712\tvalid_1's Averge Precision: 0.755176\n",
      "[400]\ttraining's Averge Precision: 0.912792\tvalid_1's Averge Precision: 0.758978\n",
      "[500]\ttraining's Averge Precision: 0.923639\tvalid_1's Averge Precision: 0.761613\n",
      "[600]\ttraining's Averge Precision: 0.932227\tvalid_1's Averge Precision: 0.762999\n",
      "[700]\ttraining's Averge Precision: 0.939464\tvalid_1's Averge Precision: 0.764029\n",
      "[800]\ttraining's Averge Precision: 0.945169\tvalid_1's Averge Precision: 0.764774\n",
      "[900]\ttraining's Averge Precision: 0.95048\tvalid_1's Averge Precision: 0.765266\n",
      "[1000]\ttraining's Averge Precision: 0.954695\tvalid_1's Averge Precision: 0.76622\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's Averge Precision: 0.954695\tvalid_1's Averge Precision: 0.76622\n",
      "Summary:\n",
      "LGBM Testing_Set average_precision_score 0.790665\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBM_Model(input_features)\n",
    "oof_preds_LGBM, df_sub_preds_LGBM, clf = lgbm.run(X_train, y_train, groups, X_test, lgbm.lgbm_averge_precision\n",
    "                                                  , n_splits = 10, model_name='First_Fraudulent_Transaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_sub_preds_statistics = generate_statistic(df_sub_preds_LGBM)\n",
    "df_sub_preds_statistics['mean_remove_outlier'] = df_sub_preds_statistics.apply(remove_outlier, axis = 1)\n",
    "df_train['oof_first_fraud_model'] = oof_preds_LGBM\n",
    "df_test['sub_first_fraud_model'] = df_sub_preds_statistics['mean_remove_outlier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "跑完\n"
     ]
    }
   ],
   "source": [
    "print('跑完')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the range of threshold which maximizes the f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.026398347233912316\n",
      "1 0.3465040024912532\n",
      "2 0.42884876268887123\n",
      "3 0.4811164741788456\n",
      "4 0.5194893667436763\n",
      "5 0.547837567004406\n",
      "6 0.568708623145898\n",
      "7 0.585598373727284\n",
      "8 0.5994000545404963\n",
      "9 0.6110746744120679\n",
      "10 0.6203671631451333\n",
      "11 0.6289935000984833\n",
      "12 0.6357821049243643\n",
      "13 0.6416928092513994\n",
      "14 0.6467335739770902\n",
      "15 0.6514675941635562\n",
      "16 0.6567781993790963\n",
      "17 0.6610543808628343\n",
      "18 0.6639050108546364\n",
      "19 0.6664571595322004\n",
      "20 0.6688048769391748\n",
      "21 0.6717451842305125\n",
      "22 0.6724917284123212\n",
      "23 0.674572921078639\n",
      "24 0.676664210851534\n",
      "25 0.6776950780312125\n",
      "26 0.6795334965933615\n",
      "27 0.6809374694197085\n",
      "28 0.6822390676312996\n",
      "29 0.6835159362549801\n",
      "30 0.684379547393246\n",
      "31 0.6846432094705689\n",
      "32 0.6852758233914551\n",
      "33 0.6860972728673412\n",
      "34 0.6862227740700501\n",
      "35 0.6863788068418857\n",
      "36 0.6860141695093152\n",
      "37 0.6861279158851347\n",
      "38 0.6860242501595406\n",
      "39 0.685500066943366\n",
      "40 0.684969151601692\n",
      "41 0.683969300029832\n",
      "42 0.6830359578763573\n",
      "43 0.6821760719870511\n",
      "44 0.6819322978453388\n",
      "45 0.6805382161187404\n",
      "46 0.6799776910206358\n",
      "47 0.678051653066375\n",
      "48 0.6775583786372215\n",
      "49 0.6767376729186115\n",
      "50 0.6761620469083155\n",
      "51 0.6741341867642017\n",
      "52 0.6733873283933597\n",
      "53 0.671839395425308\n",
      "54 0.6705493741307371\n",
      "55 0.6695186543274547\n",
      "56 0.6678949523308182\n",
      "57 0.6662748324908899\n",
      "58 0.6646793187922435\n",
      "59 0.6635248088209141\n",
      "60 0.662146489428138\n",
      "61 0.6597778043244535\n",
      "62 0.6575268494630107\n",
      "63 0.6558196992979602\n",
      "64 0.6538356786200635\n",
      "65 0.6516136874734091\n",
      "66 0.6489904389528668\n",
      "67 0.6471562672556599\n",
      "68 0.6450956827216419\n",
      "69 0.642445998638361\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,70):# train到這\n",
    "    print (i, f1_score(y_train, np.where(df_train['oof_base_model']>i/100,1,0) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different models to predict based on different condiitons. Change the threshold to create submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.35\n",
    "\n",
    "# Use base model for default\n",
    "df_test['fraud_ind'] = np.where(df_test['sub_base_model']> threshold, 1, 0)\n",
    "\n",
    "df_test['fraud_ind'] = np.where((df_test['mchno_in_fraud_mchno_list']==1) & (df_test['sub_fraud_mchno_model'] > threshold), 1, df_test['fraud_ind'])\n",
    "df_test['fraud_ind'] = np.where((df_test['mchno_in_fraud_mchno_list']==1) & (df_test['sub_fraud_mchno_model'] <= threshold), 0, df_test['fraud_ind'])\n",
    "\n",
    "df_test['fraud_ind'] = np.where((df_test['mchno_in_fraud_mchno_list']==0) & (df_test['diff_with_first_fraud_locdt'] >= 1) & (df_test['sub_first_fraud_model'] > threshold), 1, df_test['fraud_ind'])\n",
    "\n",
    "df_test['fraud_ind'] = np.where((df_test['mchno_in_fraud_mchno_list']==0) & (df_test['mchno_in_normal_mchno_list']>0) & (df_test['sub_normal_mchno_model'] > threshold), 1, df_test['fraud_ind'])\n",
    "df_test['fraud_ind'] = np.where((df_test['mchno_in_fraud_mchno_list']==0) & (df_test['mchno_in_normal_mchno_list']>0) & (df_test['sub_normal_mchno_model'] <= threshold), 0, df_test['fraud_ind'])\n",
    "\n",
    "df_test['fraud_ind'] = np.where((df_test['mchno_in_fraud_mchno_list']==0) & (df_test['conam_in_fraud_conam_list']==1) & (df_test['sub_fraud_conam_model'] > threshold), 1, df_test['fraud_ind'])\n",
    "df_test['fraud_ind'] = np.where((df_test['mchno_in_fraud_mchno_list']==0) & (df_test['conam_in_fraud_conam_list']==1) & (df_test['sub_fraud_conam_model'] <= threshold), 0, df_test['fraud_ind'])\n",
    "\n",
    "df_test[['txkey','fraud_ind']].to_csv('submission_{}.csv'.format(threshold),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
